{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEDANd6WdBZe",
        "outputId": "f2f25638-5319-4bbf-c6ce-76d5cb060872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (28.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages: faker for generating fake PII data, transformers for text generation\n",
        "!pip install faker\n",
        "!pip install transformers\n",
        "\n",
        "# Import necessary libraries\n",
        "import random   # Used for random selections and shuffling\n",
        "import re       # Regular expressions to detect patterns for PII redaction\n",
        "from faker import Faker  # Faker is used to generate synthetic data\n",
        "from transformers import pipeline  # Transformers provide pre-trained models for NLP tasks like text generation\n",
        "from faker.providers import internet, bank, person, phone_number, misc  # Specialized providers for Faker\n",
        "import string   # Useful for character manipulations, such as creating random strings\n",
        "\n",
        "# Initialize the Faker object, which will help generate various types of fake data\n",
        "fake = Faker()\n",
        "\n",
        "# Adding specific providers to generate specialized fake data (internet, bank, personal details, etc.)\n",
        "fake.add_provider(internet)\n",
        "fake.add_provider(bank)\n",
        "fake.add_provider(person)\n",
        "fake.add_provider(phone_number)\n",
        "fake.add_provider(misc)\n",
        "\n",
        "# At this point, we are ready to generate realistic fake PII data for further redaction in the program."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define various PII Data Templates for synthetic Data Generation"
      ],
      "metadata": {
        "id": "aAe1ARyhXpHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom templates for fake PII data generation. Generated Synthetic dataset will be used for training the model.\n",
        "custom_templates = [\n",
        "\n",
        "    # Template 1-5\n",
        "    \"On [DATE_TIME], [PERSON] of nationality [NRP], residing at [LOCATION], updated their payment method to a card ending in [CREDIT_CARD]. A confirmation was sent to [EMAIL_ADDRESS] from IP [IP_ADDRESS].\",\n",
        "    \"A transfer to [IBAN_CODE] from [BANK_NUMBER] was initiated on [DATE_TIME] by [PERSON], holder of passport [PASSPORT]. Any queries should be directed to [PHONE_NUMBER] or [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON], holding a driver's license [DRIVER_LICENSE] from [LOCATION], reported a misplaced wallet containing a card [CREDIT_CARD] and SSN [SSN] on [DATE_TIME].\",\n",
        "    \"User [PERSON], with ITIN [ITIN], accessed [URL] on [DATE_TIME] from IP [IP_ADDRESS]. For account support related to [BANK_NUMBER], contact [PHONE_NUMBER].\",\n",
        "    \"Customer [PERSON] requested an account statement for [BANK_NUMBER] to be mailed to [LOCATION]. For further assistance, reach out to [EMAIL_ADDRESS] or [PHONE_NUMBER].\",\n",
        "\n",
        "    # Template 6-10\n",
        "    \"On [DATE_TIME], [PERSON] from [LOCATION] called customer support from [PHONE_NUMBER] regarding an unrecognized charge on their bank statement [BANK_NUMBER].\",\n",
        "    \"[PERSON] visited the branch at [LOCATION] on [DATE_TIME] to open a new account with IBAN [IBAN_CODE]. Contact details: [PHONE_NUMBER] and [EMAIL_ADDRESS].\",\n",
        "    \"Email alert for [PERSON]: Your new card [CREDIT_CARD] is now linked to the account [BANK_NUMBER]. For security, this change was recorded from IP [IP_ADDRESS].\",\n",
        "    \"A parcel for [PERSON] with ITIN [ITIN] is awaiting pickup at [LOCATION]. Please present your driver's license [DRIVER_LICENSE] and SSN [SSN] for identification.\",\n",
        "    \"Our records show [PERSON], nationality [NRP], booked a flight using passport number [PASSPORT]. Confirmation was sent to [EMAIL_ADDRESS] and can be tracked at [URL].\",\n",
        "\n",
        "    # Template 11-15\n",
        "    \"Security notice for [PERSON]: An attempt to access [URL] with your credentials was made on [DATE_TIME] from IP [IP_ADDRESS]. If this wasn't you, contact us at [PHONE_NUMBER].\",\n",
        "    \"[PERSON]'s appointment for passport renewal [PASSPORT] is set for [DATE_TIME] at [LOCATION]. The confirmation email is sent to [EMAIL_ADDRESS].\",\n",
        "    \"During our regular audit on [DATE_TIME], we verified the account [BANK_NUMBER] and ITIN [ITIN] for [PERSON] against the national database [NRP].\",\n",
        "    \"The car rental for [PERSON] with driver's license [DRIVER_LICENSE] was processed on [DATE_TIME]. The transaction ID [IBAN_CODE] was sent to [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON], residing at [LOCATION], updated their contact information to [PHONE_NUMBER] and [EMAIL_ADDRESS]. Their account [BANK_NUMBER] and SSN [SSN] were noted for the update.\",\n",
        "\n",
        "    # Template 16-20\n",
        "    \"Our new client [PERSON] with ITIN [ITIN] has registered for online banking. Account [BANK_NUMBER], IP [IP_ADDRESS], email [EMAIL_ADDRESS] are now linked.\",\n",
        "    \"Confirmation for [PERSON]: Your transaction to [IBAN_CODE] from account [BANK_NUMBER] is complete. Details were sent to [EMAIL_ADDRESS] and can be reviewed at [URL].\",\n",
        "    \"Notice for [PERSON]: Your recent application using SSN [SSN] and driver's license [DRIVER_LICENSE] has been approved. Please confirm your email [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] reported losing their passport [PASSPORT] at [LOCATION] on [DATE_TIME]. A temporary hold has been placed on their bank account [BANK_NUMBER].\",\n",
        "    \"A new connection from IP [IP_ADDRESS] was detected on [DATE_TIME] for [PERSON]'s account. Please verify recent activities with your bank [BANK_NUMBER].\",\n",
        "\n",
        "    # Template 21-25\n",
        "    \"Subscription for [PERSON] with email [EMAIL_ADDRESS] was renewed on [DATE_TIME]. For billing inquiries about bank number [BANK_NUMBER] or card [CREDIT_CARD], call [PHONE_NUMBER].\",\n",
        "    \"[PERSON], with nationality [NRP], scheduled a service at [LOCATION] for [DATE_TIME]. Confirmation sent to [EMAIL_ADDRESS]. Remember to bring ID [DRIVER_LICENSE] and SSN [SSN].\",\n",
        "    \"Account [BANK_NUMBER] owned by [PERSON] was accessed on [DATE_TIME] from new IP [IP_ADDRESS]. Verify the activity through [URL] or contact support at [PHONE_NUMBER].\",\n",
        "    \"New login to [URL] by [PERSON] using ITIN [ITIN] from [IP_ADDRESS] on [DATE_TIME]. If this wasn't you, please notify us immediately at [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] requested a copy of the transaction with IBAN [IBAN_CODE] to be sent to [EMAIL_ADDRESS]. For more details, visit [URL] or dial [PHONE_NUMBER].\",\n",
        "\n",
        "    # Template 26-30\n",
        "    \"[PERSON] with SSN [SSN] reported an error with the payment portal [URL] on [DATE_TIME]. Tech support is investigating the IP [IP_ADDRESS] and bank number [BANK_NUMBER].\",\n",
        "    \"Customer notice for [PERSON]: Your driver's license [DRIVER_LICENSE] and passport [PASSPORT] need renewal before [DATE_TIME]. Visit [LOCATION] or contact [PHONE_NUMBER].\",\n",
        "    \"[PERSON]'s profile updated. New address [LOCATION], phone [PHONE_NUMBER], email [EMAIL_ADDRESS], and bank details [BANK_NUMBER] confirmed on [DATE_TIME].\",\n",
        "    \"Registration completed: [PERSON], nationality [NRP], with ITIN [ITIN]. Credentials sent to [EMAIL_ADDRESS]. Log in from [IP_ADDRESS] to confirm and complete setup.\",\n",
        "    \"Security update: [PERSON], your password for account [BANK_NUMBER] was reset on [DATE_TIME]. A notification was sent to [EMAIL_ADDRESS] from [IP_ADDRESS].\",\n",
        "\n",
        "    # Template 31-35\n",
        "    \"Order confirmation for [PERSON]: Shipment to [LOCATION] will arrive on [DATE_TIME]. Tracking available at [URL]. Contact us at [PHONE_NUMBER] for issues.\",\n",
        "    \"[PERSON]'s credit card [CREDIT_CARD] was charged on [DATE_TIME] for the purchase. Receipt sent to [EMAIL_ADDRESS]. Call [PHONE_NUMBER] for disputes.\",\n",
        "    \"Job application received from [PERSON] on [DATE_TIME] for position in [LOCATION]. Applicant SSN [SSN] and email [EMAIL_ADDRESS] recorded for follow-up.\",\n",
        "    \"Insurance claim filed by [PERSON] with policy number [BANK_NUMBER]. Accident report from [DATE_TIME] at [LOCATION] logged. Contact [PHONE_NUMBER] for status.\",\n",
        "    \"[PERSON] reported a missing passport [PASSPORT] to authorities at [LOCATION] on [DATE_TIME]. A temporary document was issued and sent to [EMAIL_ADDRESS].\",\n",
        "\n",
        "    # Template 36-40\n",
        "    \"[PERSON] updated their emergency contact details to [PHONE_NUMBER]. The security question linked to SSN [SSN] and bank account [BANK_NUMBER] was also updated.\",\n",
        "    \"Alert: Unauthorized login attempt on [PERSON]'s account [BANK_NUMBER] detected from IP [IP_ADDRESS] on [DATE_TIME]. Verify identity with ITIN [ITIN] at [URL].\",\n",
        "    \"[PERSON], residing at [LOCATION], updated contact information. New phone [PHONE_NUMBER], email [EMAIL_ADDRESS], and driver's license [DRIVER_LICENSE] number recorded.\",\n",
        "    \"Welcome [PERSON] to our service! Your account [BANK_NUMBER] is now active. Log in from [IP_ADDRESS], or call us at [PHONE_NUMBER] for support.\",\n",
        "    \"Final notice for [PERSON]: Credit card [CREDIT_CARD] payment overdue as of [DATE_TIME]. Access to account [BANK_NUMBER] may be restricted. Contact [EMAIL_ADDRESS].\",\n",
        "\n",
        "    # Template 41-45\n",
        "    \"Email to [PERSON]: Your recent transaction from [IBAN_CODE] has been flagged. Please verify recent activity using your SSN [SSN] at [URL].\",\n",
        "    \"[PERSON] with driver's license [DRIVER_LICENSE] requested roadside assistance at [LOCATION] on [DATE_TIME]. For updates, contact [PHONE_NUMBER].\",\n",
        "    \"New device setup by [PERSON] completed. IP [IP_ADDRESS] and device ID linked to email [EMAIL_ADDRESS] and bank account [BANK_NUMBER].\",\n",
        "    \"Customer [PERSON] made a purchase on [DATE_TIME] using card [CREDIT_CARD]. A loyalty discount was applied. Email [EMAIL_ADDRESS] for membership details.\",\n",
        "    \"[PERSON] with nationality [NRP] applied for a travel visa. Application ID [PASSPORT] and contact [EMAIL_ADDRESS] have been logged for processing.\",\n",
        "\n",
        "    # Template 46-50\n",
        "    \"Alarm raised for [PERSON] at [DATE_TIME]: An attempt to access [URL] using [IP_ADDRESS] with the email [EMAIL_ADDRESS]. Bank account [BANK_NUMBER] has been put on hold.\",\n",
        "    \"[PERSON] confirmed their attendance for the webinar on [DATE_TIME] at [LOCATION]. Registration details: SSN [SSN], contact [PHONE_NUMBER], and nationality [NRP].\",\n",
        "    \"Update received from [PERSON]: Change of address to [LOCATION] and phone to [PHONE_NUMBER] was noted. New driver's license [DRIVER_LICENSE] was issued and sent to [EMAIL_ADDRESS].\",\n",
        "    \"Guest [PERSON] with passport number [PASSPORT] checked in at [LOCATION] on [DATE_TIME]. Billing info: credit card [CREDIT_CARD], contact email [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] with ITIN [ITIN] booked a consultation on [DATE_TIME]. IP address [IP_ADDRESS] and bank details [BANK_NUMBER] were verified for the appointment.\",\n",
        "\n",
        "    # Template 51-55\n",
        "    \"[PERSON]'s transaction to [IBAN_CODE] from account [BANK_NUMBER] was completed on [DATE_TIME]. For security, SSN [SSN] was verified and email confirmation sent to [EMAIL_ADDRESS].\",\n",
        "    \"Car loan approved for [PERSON] on [DATE_TIME]. Vehicle to be picked up at [LOCATION]. Loan details: account [BANK_NUMBER], phone [PHONE_NUMBER].\",\n",
        "    \"Passport application for [PERSON] with nationality [NRP] processed. New passport [PASSPORT] will be mailed to [LOCATION]. Confirmation to [EMAIL_ADDRESS].\",\n",
        "    \"Profile update for [PERSON] successful: new email [EMAIL_ADDRESS], phone [PHONE_NUMBER], and SSN [SSN]. Visit [URL] to review changes or call support.\",\n",
        "    \"[PERSON], residing at [LOCATION], reported a lost credit card [CREDIT_CARD] to the hotline [PHONE_NUMBER] on [DATE_TIME]. A freeze was placed on their account [BANK_NUMBER].\",\n",
        "\n",
        "    # Template 56-60\n",
        "    \"Welcome message sent to [PERSON] at [EMAIL_ADDRESS]. Instructions to set up their new account [BANK_NUMBER] are included. IP [IP_ADDRESS] was used for signup.\",\n",
        "    \"[PERSON] requested a credit increase for card [CREDIT_CARD] on [DATE_TIME]. New terms sent to [EMAIL_ADDRESS]. For questions, contact [PHONE_NUMBER].\",\n",
        "    \"[PERSON] updated their billing address for bank account [BANK_NUMBER] to [LOCATION]. New card [CREDIT_CARD] will be dispatched to this address.\",\n",
        "    \"On [DATE_TIME], [PERSON] with ITIN [ITIN] and SSN [SSN] requested a payment deferral. The call was logged at [PHONE_NUMBER], and notes were sent to [EMAIL_ADDRESS].\",\n",
        "    \"Alert for [PERSON]: Your IP [IP_ADDRESS] was used to schedule a payment to [IBAN_CODE] on [DATE_TIME]. If this was not authorized, please contact [PHONE_NUMBER].\",\n",
        "\n",
        "    # Template 61-65\n",
        "    \"[PERSON] with nationality [NRP] reviewed their transaction history for account [BANK_NUMBER] on [URL] and flagged an issue to [EMAIL_ADDRESS].\",\n",
        "    \"Notification: [PERSON]'s driver's license [DRIVER_LICENSE] is set to expire on [DATE_TIME]. Renewal details have been sent to [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] with passport [PASSPORT] booked a rental at [LOCATION]. Contact number [PHONE_NUMBER] provided for any changes to the booking.\",\n",
        "    \"New IP address [IP_ADDRESS] logged for [PERSON]'s account on [DATE_TIME]. Confirm changes via [EMAIL_ADDRESS] or call [PHONE_NUMBER].\",\n",
        "    \"Password reset request for [PERSON] was received from IP [IP_ADDRESS]. To confirm, use SSN [SSN] and bank number [BANK_NUMBER], or contact [PHONE_NUMBER].\",\n",
        "\n",
        "    # Template 66-70\n",
        "    \"[PERSON] with ITIN [ITIN] made a purchase on [URL] on [DATE_TIME]. Shipping to [LOCATION]. Payment was made using bank account [BANK_NUMBER].\",\n",
        "    \"Confirmation for [PERSON]: IT support has reset your password for account [BANK_NUMBER] as requested. For any issues, email [EMAIL_ADDRESS] or call [PHONE_NUMBER].\",\n",
        "    \"[PERSON]'s new credit card [CREDIT_CARD] was activated on [DATE_TIME] after identity verification with SSN [SSN] was completed. Confirmation email sent to [EMAIL_ADDRESS].\",\n",
        "\n",
        "   # Template 71-75\n",
        "    \"[PERSON] signed up for a subscription service using credit card [CREDIT_CARD] and SSN [SSN] on [DATE_TIME]. Contact support at [PHONE_NUMBER] for changes.\",\n",
        "    \"[PERSON] with ITIN [ITIN] registered for an event at [LOCATION] on [DATE_TIME]. A confirmation email was sent to [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] reported a fraudulent charge on their card [CREDIT_CARD] on [DATE_TIME]. Contact details: [PHONE_NUMBER], [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] filed a dispute over the transaction made to [IBAN_CODE] on [DATE_TIME]. Bank account [BANK_NUMBER] and IP [IP_ADDRESS] were flagged.\",\n",
        "    \"[PERSON] updated their payment details for account [BANK_NUMBER] with IBAN [IBAN_CODE]. New email [EMAIL_ADDRESS] and phone [PHONE_NUMBER] were confirmed.\",\n",
        "\n",
        "    # Template 76-80\n",
        "    \"A loan application by [PERSON] using SSN [SSN] and bank account [BANK_NUMBER] was submitted on [DATE_TIME]. Confirmation sent to [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] changed their billing address for their credit card [CREDIT_CARD] to [LOCATION] on [DATE_TIME].\",\n",
        "    \"[PERSON] logged in from IP [IP_ADDRESS] on [DATE_TIME] to review their transaction history for account [BANK_NUMBER].\",\n",
        "    \"Account update: [PERSON]'s driver's license [DRIVER_LICENSE] and SSN [SSN] were verified on [DATE_TIME] for transaction ID [IBAN_CODE].\",\n",
        "    \"New card [CREDIT_CARD] linked to [PERSON]'s account [BANK_NUMBER] was activated on [DATE_TIME]. Confirmation email sent to [EMAIL_ADDRESS].\",\n",
        "\n",
        "    # Template 81-85\n",
        "    \"[PERSON]'s request to update email [EMAIL_ADDRESS] for account [BANK_NUMBER] was processed on [DATE_TIME].\",\n",
        "    \"A change in address for [PERSON]'s account [BANK_NUMBER] was logged at [LOCATION] on [DATE_TIME].\",\n",
        "    \"[PERSON] logged into [URL] from IP [IP_ADDRESS] to review transactions for [BANK_NUMBER]. Contact [PHONE_NUMBER] for assistance.\",\n",
        "    \"Notification: [PERSON]'s request to transfer funds from [BANK_NUMBER] to IBAN [IBAN_CODE] was completed on [DATE_TIME].\",\n",
        "    \"[PERSON]'s SSN [SSN] and passport [PASSPORT] were verified for an application submitted on [DATE_TIME].\",\n",
        "\n",
        "    # Template 86-90\n",
        "    \"[PERSON] confirmed a payment using card [CREDIT_CARD] on [DATE_TIME].\",\n",
        "    \"A travel booking for [PERSON] with passport [PASSPORT] was completed on [DATE_TIME] and confirmed at [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON]'s ITIN [ITIN] and driver's license [DRIVER_LICENSE] were used to process a transaction on [DATE_TIME].\",\n",
        "    \"Profile update: [PERSON]'s new email [EMAIL_ADDRESS] and phone number [PHONE_NUMBER] were confirmed on [DATE_TIME].\",\n",
        "    \"[PERSON]'s application for a loan using SSN [SSN] was approved on [DATE_TIME].\",\n",
        "\n",
        "    # Template 91-95\n",
        "    \"[PERSON] flagged a suspicious transaction made to [IBAN_CODE] from account [BANK_NUMBER] on [DATE_TIME].\",\n",
        "    \"A request to update [PERSON]'s email [EMAIL_ADDRESS] was submitted on [DATE_TIME]. Contact [PHONE_NUMBER] for any issues.\",\n",
        "    \"[PERSON]'s account [BANK_NUMBER] was accessed from IP [IP_ADDRESS] on [DATE_TIME]. Verification code sent to [EMAIL_ADDRESS].\",\n",
        "    \"New application for [PERSON] was submitted on [DATE_TIME] using SSN [SSN] and passport [PASSPORT].\",\n",
        "    \"[PERSON] confirmed their identity with ITIN [ITIN] and email [EMAIL_ADDRESS] on [DATE_TIME].\",\n",
        "\n",
        "    # Template 96-100\n",
        "    \"[PERSON]'s card [CREDIT_CARD] was used to make a purchase on [DATE_TIME]. Confirmation sent to [EMAIL_ADDRESS].\",\n",
        "    \"A parcel for [PERSON] is awaiting pickup at [LOCATION]. Driver's license [DRIVER_LICENSE] and SSN [SSN] will be needed for verification.\",\n",
        "    \"[PERSON] requested assistance with a payment made to IBAN [IBAN_CODE] on [DATE_TIME]. Contact support at [PHONE_NUMBER] or [EMAIL_ADDRESS].\",\n",
        "    \"[PERSON] updated their SSN [SSN] and phone [PHONE_NUMBER] for their account [BANK_NUMBER] on [DATE_TIME].\",\n",
        "    \"[PERSON]'s new driver's license [DRIVER_LICENSE] was issued on [DATE_TIME] and sent to their registered email [EMAIL_ADDRESS].\"\n",
        "]\n",
        "\n",
        "# Define a list of common religions for the templates.\n",
        "religions = [\n",
        "    'Christianity', 'Islam', 'Hinduism', 'Buddhism', 'Sikhism',\n",
        "    'Judaism', 'Baha\\'i', 'Jainism', 'Shinto', 'Cao Dai',\n",
        "    'Zoroastrianism', 'Tenrikyo', 'Animism', 'Neo-Paganism',\n",
        "    'Unitarian Universalism', 'Rastafarianism'\n",
        "]\n",
        "\n",
        "# Define political affiliations to fill in relevant placeholders in templates.\n",
        "political_groups = [\n",
        "    'Democrat', 'Republican', 'Independent', 'Libertarian', 'Green',\n",
        "    'Conservative', 'Liberal', 'Socialist', 'Communist', 'Centrist',\n",
        "    'Progressive', 'Anarchist', 'Monarchist', 'Fascist', 'Nationalist',\n",
        "    'Populist'\n",
        "]\n",
        "\n",
        "# Generate a list of 150 unique countries using the Faker library's 'country()' method.\n",
        "nationalities = [fake.country() for _ in range(150)]\n",
        "\n",
        "# Ensure the nationalities list contains unique values by converting it to a set.\n",
        "nationalities = list(set(nationalities))\n",
        "\n",
        "# print (nationalities)"
      ],
      "metadata": {
        "id": "S1pS5EkHd8Z9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic PII dataset generation"
      ],
      "metadata": {
        "id": "z-R_2RaHMh0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions to generate different types of PII data\n",
        "\n",
        "from faker.providers import date_time\n",
        "\n",
        "# Initialize the GPT-2 based text generator using the distilgpt2 model\n",
        "text_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "\n",
        "# Function to generate random email addresses using Faker and predefined domain types\n",
        "def create_email():\n",
        "    user_name = fake.user_name()\n",
        "    domain_types = ['free', 'isp', 'custom']\n",
        "    domain_type = random.choice(domain_types)\n",
        "\n",
        "    if domain_type == 'free':\n",
        "        domains = ['gmail.com', 'yahoo.com', 'hotmail.com']\n",
        "        domain = random.choice(domains)\n",
        "        email = f\"{user_name}@{domain}\"\n",
        "    elif domain_type == 'isp':\n",
        "        domains = ['comcast.net', 'verizon.net', 'att.net']\n",
        "        domain = random.choice(domains)\n",
        "        email = f\"{user_name}@{domain}\"\n",
        "    else:  # custom_domain\n",
        "        domain = fake.domain_name()\n",
        "        email = f\"{user_name}@{domain}\"\n",
        "    return email\n",
        "\n",
        "# Function to generate a random SSN (Social Security Number) in a standard format\n",
        "def create_ssn():\n",
        "    # Generate SSN with blocks of random numbers\n",
        "    part1 = random.randint(100, 999)\n",
        "    part2 = random.randint(10, 99)\n",
        "    part3 = random.randint(1000, 9999)\n",
        "    return f\"{part1}-{part2}-{part3}\"\n",
        "\n",
        "# Function to generate a passport number with random alphanumeric characters\n",
        "def create_passport():\n",
        "    # Generate Passport Number with alphanumeric characters and diverse lengths\n",
        "    length = random.choice([8, 9])  # Common lengths\n",
        "    letters = string.ascii_uppercase\n",
        "    digits = string.digits\n",
        "    return ''.join(random.choice(letters + digits) for _ in range(length))\n",
        "\n",
        "# Function to generate a realistic driver's license number based on state abbreviations\n",
        "def create_driver_license():\n",
        "    state_abbr = fake.state_abbr()\n",
        "    numeric_part = ''.join(random.choices(string.digits, k=random.randint(5, 8)))\n",
        "    format_choice = random.choice(['letters', 'numeric', 'mixed'])\n",
        "    if format_choice == 'letters':\n",
        "        letter_part = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
        "        license_number = f\"{state_abbr}-{letter_part}{numeric_part}\"\n",
        "    elif format_choice == 'numeric':\n",
        "        license_number = f\"{state_abbr}-{numeric_part}\"\n",
        "    else:  # mixed\n",
        "        mixed_part = ''.join(random.choices(string.ascii_uppercase + string.digits, k=2))\n",
        "        license_number = f\"{state_abbr}-{mixed_part}{numeric_part}\"\n",
        "    return license_number\n",
        "\n",
        "\n",
        "# Function to generate a credit card number with optional formatting (spaces, dashes, none)\n",
        "def create_card_number():\n",
        "    card_number = fake.credit_card_number(card_type=None)  # Generate a basic card number\n",
        "    format_choice = random.choice(['spaces', 'dashes', 'none'])\n",
        "\n",
        "    if format_choice == 'spaces':\n",
        "        # Format with spaces every 4 digits\n",
        "        formatted_card_number = ' '.join(card_number[i:i+4] for i in range(0, len(card_number), 4))\n",
        "    elif format_choice == 'dashes':\n",
        "        # Format with dashes every 4 digits\n",
        "        formatted_card_number = '-'.join(card_number[i:i+4] for i in range(0, len(card_number), 4))\n",
        "    else:\n",
        "        # No formatting applied\n",
        "        formatted_card_number = card_number\n",
        "\n",
        "    return formatted_card_number\n",
        "\n",
        "# Function to generate a datetime in a random, common format\n",
        "def create_date_time():\n",
        "    # Define a list of common date-time formats\n",
        "    formats = [\n",
        "        \"%Y-%m-%d %H:%M:%S\",  # 2024-03-27 14:20:12\n",
        "        \"%d/%m/%Y %I:%M %p\",  # 27/03/2024 02:20 PM\n",
        "        \"%A, %B %d, %Y\",      # Saturday, March 27, 2024\n",
        "        \"%d-%b-%Y %H:%M\",     # 27-Mar-2024 14:20\n",
        "    ]\n",
        "    # Choose a random format\n",
        "    chosen_format = random.choice(formats)\n",
        "    # Generate a datetime string in the chosen format\n",
        "    return fake.date_time().strftime(chosen_format)\n",
        "\n",
        "# Function to generate a phone number in various formats (international, dashed, dotted)\n",
        "def create_phone():\n",
        "    format_choice = random.choice(['international', 'dashes', 'dots'])\n",
        "    if format_choice == 'international':\n",
        "        phone_number = f\"+{fake.country_calling_code()} {fake.phone_number()}\"\n",
        "    elif format_choice == 'dashes':\n",
        "        phone_number = fake.phone_number().replace(' ', '-')\n",
        "    elif format_choice == 'dots':\n",
        "        phone_number = fake.phone_number().replace(' ', '.')\n",
        "    return phone_number\n",
        "\n",
        "# Function to generates a random International Bank Account Number (IBAN)\n",
        "def create_iban_code():\n",
        "    iban_number = fake.iban()\n",
        "    format_choice = random.choice(['spaces', 'none'])\n",
        "    if format_choice == 'spaces':\n",
        "        formatted_iban_number = ' '.join(iban_number[i:i+4] for i in range(0, len(iban_number), 4))\n",
        "    else:\n",
        "        formatted_iban_number = iban_number\n",
        "    return formatted_iban_number\n",
        "\n",
        "# Function to generates a random IPv4 or an IPv6 address\n",
        "def create_ip_address():\n",
        "    format_choice = random.choice(['ipv4', 'ipv6'])\n",
        "    if format_choice == 'ipv4':\n",
        "        ip_address = fake.ipv4()\n",
        "    else:\n",
        "        ip_address = fake.ipv6()\n",
        "    return ip_address\n",
        "\n",
        "# Function to randomly selects a value from either nationality, religion, or political group lists\n",
        "def generate_nrp():\n",
        "    # Randomly choose between nationality, religion, or political group\n",
        "    choice = random.choice(['nationality', 'religion', 'political_group'])\n",
        "    if choice == 'nationality':\n",
        "        return random.choice(nationalities)\n",
        "    elif choice == 'religion':\n",
        "        return random.choice(religions)\n",
        "    else:\n",
        "        return random.choice(political_groups)\n",
        "\n",
        "# Function to create a random location\n",
        "def create_location():\n",
        "    format_choice = random.choice(['city_only', 'city_country', 'full_address'])\n",
        "    if format_choice == 'city_only':\n",
        "        location = fake.city()\n",
        "    elif format_choice == 'city_country':\n",
        "        location = f\"{fake.city()}, {fake.country()}\"\n",
        "    else:  # full_address for more detail\n",
        "        location = fake.address().replace(\"\\n\", \", \")\n",
        "    return location\n",
        "\n",
        "# Function to create random person names\n",
        "def create_person_name():\n",
        "    format_choice = random.choice(['simple', 'with_middle_initial', 'with_title'])\n",
        "    if format_choice == 'simple':\n",
        "        person_name = fake.name()\n",
        "    elif format_choice == 'with_middle_initial':\n",
        "        first_name, last_name = fake.first_name(), fake.last_name()\n",
        "        middle_initial = random.choice(string.ascii_uppercase)\n",
        "        person_name = f\"{first_name} {middle_initial}. {last_name}\"\n",
        "    else:  # with_title\n",
        "        title = random.choice(['Mr.', 'Ms.', 'Dr.', 'Prof.'])\n",
        "        person_name = f\"{title} {fake.name()}\"\n",
        "    return person_name\n",
        "\n",
        "# Function to create random urls\n",
        "def create_url():\n",
        "    # Protocols\n",
        "    protocol = random.choice(['http', 'https'])\n",
        "\n",
        "    # Subdomains and domains\n",
        "    subdomain = random.choice(['www', 'app', 'blog', '', 'store', 'secure', 'mail'])\n",
        "    domain = fake.domain_name()\n",
        "\n",
        "    # Top-Level Domains (TLDs)\n",
        "    tld = random.choice(['com', 'org', 'net', 'io', 'co.uk', 'info', 'biz', 'edu'])\n",
        "\n",
        "    # Paths\n",
        "    paths = [\n",
        "        '', '/home', '/contact-us', '/products', '/products/item', '/search',\n",
        "        '/user/profile', '/login', '/signup', '/about', '/help', '/settings'\n",
        "    ]\n",
        "    path = random.choice(paths)\n",
        "\n",
        "    # Query Parameters\n",
        "    query_parameters = [\n",
        "        '', '?ref=homepage', '?utm_source=google', '?q=searchTerm', '?page=2',\n",
        "        '?sort=asc&order=price', '?id=12345', '?filter=active', '?lang=en'\n",
        "    ]\n",
        "    query = random.choice(query_parameters)\n",
        "\n",
        "    # Fragments\n",
        "    fragments = ['', '#section', '#comments', '#top', '#details', '#contact']\n",
        "    fragment = random.choice(fragments)\n",
        "\n",
        "    # Assemble the URL\n",
        "    if subdomain:\n",
        "        url = f\"{protocol}://{subdomain}.{domain}.{tld}{path}{query}{fragment}\"\n",
        "    else:\n",
        "        url = f\"{protocol}://{domain}.{tld}{path}{query}{fragment}\"\n",
        "\n",
        "    return url\n",
        "\n",
        "# Function to create random bank account numbers\n",
        "def create_bank_number():\n",
        "    account_number = ''.join(random.choices(string.digits, k=random.randint(8, 12)))\n",
        "    format_choice = random.choice(['leading_zeroes', 'dashes', 'plain'])\n",
        "    if format_choice == 'leading_zeroes':\n",
        "        account_number = f\"0{account_number}\"\n",
        "    elif format_choice == 'dashes':\n",
        "        parts = [account_number[i:i+4] for i in range(0, len(account_number), 4)]\n",
        "        account_number = '-'.join(parts)\n",
        "    # 'plain' needs no modification\n",
        "    return account_number\n",
        "\n",
        "# Function to create random ITIN\n",
        "def create_itin():\n",
        "    # Generate ITIN with more diverse formats\n",
        "    return f\"9{random.randint(70,99)}-{random.choice(['7','8'])}{random.randint(0,9)}-{random.randint(1000,9999)}\"\n",
        "\n",
        "# Function to generate one record of PII data\n",
        "def create_pii_record():\n",
        "    return {\n",
        "        'CREDIT_CARD': create_card_number(),\n",
        "        'DATE_TIME': create_date_time(),\n",
        "        'EMAIL_ADDRESS': create_email(),\n",
        "        'IBAN_CODE': create_iban_code(),\n",
        "        'IP_ADDRESS': create_ip_address(),\n",
        "        'NRP': generate_nrp(),\n",
        "        'LOCATION': create_location(),\n",
        "        'PERSON': create_person_name(),\n",
        "        'PHONE_NUMBER': create_phone(),\n",
        "        'URL': create_url(),\n",
        "        'BANK_NUMBER': create_bank_number(),\n",
        "        'DRIVER_LICENSE': create_driver_license(),\n",
        "        'ITIN': create_itin(),\n",
        "        'PASSPORT': create_passport(),\n",
        "        'SSN': create_ssn(),\n",
        "    }\n",
        "\n",
        "\n",
        "def remove_immediate_repetition(text):\n",
        "    \"\"\"Remove immediate repeated phrases in the generated text.\"\"\"\n",
        "    def replace(match):\n",
        "        return match.group(1)  # Only keep one instance of the repetition\n",
        "\n",
        "    # This regex looks for words that are followed by the same sequence\n",
        "    # It captures phrases where the repetition is immediate and exact\n",
        "    regex_pattern = r'(\\b.+\\b)(?: \\1\\b)+'\n",
        "    processed_text = re.sub(regex_pattern, replace, text)\n",
        "    return processed_text\n",
        "\n",
        "\n",
        "# Generate PII text dataset by inserting fake PII into randomly chosen custom templates\n",
        "def generate_pii_text_dataset(num_records, custom_templates):\n",
        "    pii_text_dataset = []\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        text_context = random.choice(custom_templates)\n",
        "        pii_record = create_pii_record()\n",
        "\n",
        "        generated_texts = text_generator(\n",
        "            text_context,\n",
        "            max_length=150,  # Consider reducing max_length if repetition occurs\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.8,  # Lower temperature helps reduce randomness\n",
        "            top_k=40,  # A lower top_k encourages the model to focus on more likely words\n",
        "            top_p=0.85,  # Top-p sampling can also help control randomness\n",
        "            truncation=True\n",
        "        )\n",
        "        generated_text = generated_texts[0]['generated_text']\n",
        "        generated_text = remove_immediate_repetition(generated_text)\n",
        "        pii_text = replace_pii(generated_text, pii_record)\n",
        "        pii_text_dataset.append(pii_text)\n",
        "        print(\"-\"*50)\n",
        "\n",
        "    return pii_text_dataset\n",
        "\n",
        "\n",
        "# Function to replaces placeholders in the generated template (like [CREDIT_CARD]) with actual PII data (e.g., \"1234-5678-9876-5432\").\n",
        "def replace_pii(text, pii_record):\n",
        "    placeholders = {\n",
        "        '[CREDIT_CARD]': pii_record['CREDIT_CARD'],\n",
        "        '[DATE_TIME]': pii_record['DATE_TIME'],\n",
        "        '[EMAIL_ADDRESS]': pii_record['EMAIL_ADDRESS'],\n",
        "        '[IBAN_CODE]': pii_record['IBAN_CODE'],\n",
        "        '[IP_ADDRESS]': pii_record['IP_ADDRESS'],\n",
        "        '[NRP]': pii_record['NRP'],\n",
        "        '[LOCATION]': pii_record['LOCATION'],\n",
        "        '[PERSON]': pii_record['PERSON'],\n",
        "        '[PHONE_NUMBER]': pii_record['PHONE_NUMBER'],\n",
        "        '[URL]': pii_record['URL'],\n",
        "        '[BANK_NUMBER]': pii_record['BANK_NUMBER'],\n",
        "        '[DRIVER_LICENSE]': pii_record['DRIVER_LICENSE'],\n",
        "        '[ITIN]': pii_record['ITIN'],\n",
        "        '[PASSPORT]': pii_record['PASSPORT'],\n",
        "        '[SSN]': pii_record['SSN'],\n",
        "    }\n",
        "\n",
        "    for placeholder, pii in placeholders.items():\n",
        "        # Directly replace the placeholder with the PII data, ensuring no leading/trailing spaces\n",
        "        text = text.replace(placeholder, pii.strip())\n",
        "\n",
        "    # Remove any leftover placeholders that were not in the pii_record\n",
        "    text = re.sub(r'\\[[^\\]]+\\]', '', text)\n",
        "\n",
        "    # Additional step to remove extra spaces and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with one\n",
        "    text = re.sub(r'\\n+', '\\n', text).strip()  # Replace multiple newlines with one\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def find_placeholder_order(template, pii_data):\n",
        "    placeholder_positions = []\n",
        "    for placeholder in pii_data.keys():\n",
        "        placeholder_tag = f\"[{placeholder}]\"\n",
        "        position = template.find(placeholder_tag)\n",
        "        if position != -1:\n",
        "            placeholder_positions.append((position, placeholder))\n",
        "    # Sort by position\n",
        "    placeholder_positions.sort()\n",
        "    return [placeholder for _, placeholder in placeholder_positions]\n",
        "\n",
        "# Function to update the generated text with actual PII and records the positions of PII for redaction purposes\n",
        "def generate_data_and_annotations_sequential(template, pii_data):\n",
        "    annotations = []\n",
        "    updated_text = template\n",
        "    current_offset = 0\n",
        "\n",
        "    # Determine the order in which placeholders appear in the template\n",
        "    placeholders_order = find_placeholder_order(template, pii_data)\n",
        "\n",
        "    for placeholder in placeholders_order:\n",
        "        actual_value = pii_data[placeholder]\n",
        "        placeholder_tag = f\"[{placeholder}]\"\n",
        "        start_index = updated_text.find(placeholder_tag, current_offset)\n",
        "\n",
        "        if start_index != -1:\n",
        "            end_index = start_index + len(actual_value)\n",
        "            updated_text = updated_text[:start_index] + actual_value + updated_text[start_index + len(placeholder_tag):]\n",
        "\n",
        "            annotations.append((start_index, end_index, placeholder))\n",
        "\n",
        "            # Update current_offset to the end of the last replacement to ensure correct indexing\n",
        "            current_offset = end_index\n",
        "\n",
        "    annotations.sort(key=lambda x: x[0])\n",
        "    return updated_text, annotations\n",
        "\n",
        "def generate_annotated_dataset_sequential(num_records):\n",
        "    annotated_dataset = []\n",
        "\n",
        "    for _ in range(num_records):\n",
        "        template = random.choice(custom_templates)  # Or however you choose your template\n",
        "        pii_data = create_pii_record()  # Assuming this generates your data\n",
        "\n",
        "        text, annotations = generate_data_and_annotations_sequential(template, pii_data)\n",
        "        annotated_dataset.append({\"text\": text, \"annotations\": {\"entities\": annotations}})\n",
        "\n",
        "    return annotated_dataset\n",
        "\n",
        "# Generate the dataset\n",
        "num_records = 10000  # Adjust as necessary\n",
        "annotated_dataset_sequential = generate_annotated_dataset_sequential(num_records)\n",
        "\n",
        "# Example output\n",
        "for record in annotated_dataset_sequential[:10]:\n",
        "    print(record)\n",
        "\n",
        "def convert_to_spacy_format(annotated_dataset_final):\n",
        "    spacy_training_data = []\n",
        "    for record in annotated_dataset_final:\n",
        "        entities_list = record[\"annotations\"][\"entities\"]\n",
        "        spacy_entities = [(start, end, label) for start, end, label in entities_list]\n",
        "        spacy_training_data.append((record[\"text\"], {\"entities\": spacy_entities}))\n",
        "    return spacy_training_data\n",
        "\n",
        "spacy_training_data = convert_to_spacy_format(annotated_dataset_sequential)\n",
        "print(len(spacy_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12zMlYoDd3uC",
        "outputId": "984a3a31-d5db-41c8-f630-461dea1c6e54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'User Katie Cook MD, with ITIN 999-77-1709, accessed https://mail.dean-richards.org.edu on 1990-03-13 02:10:13 from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to 025553533725, contact 2756939473.', 'annotations': {'entities': [(5, 18, 'PERSON'), (30, 41, 'ITIN'), (52, 86, 'URL'), (90, 109, 'DATE_TIME'), (118, 157, 'IP_ADDRESS'), (190, 202, 'BANK_NUMBER'), (212, 222, 'PHONE_NUMBER')]}}\n",
            "{'text': 'Nicole B. Garcia confirmed their attendance for the webinar on 19/11/2007 08:26 AM at Lake Julieville, Croatia. Registration details: SSN 115-76-4581, contact ++855 5366764295, and nationality Colombia.', 'annotations': {'entities': [(0, 16, 'PERSON'), (63, 82, 'DATE_TIME'), (86, 110, 'LOCATION'), (138, 149, 'SSN'), (159, 175, 'PHONE_NUMBER'), (193, 201, 'NRP')]}}\n",
            "{'text': 'A transfer to GB22 GOHM 0444 6516 0413 50 from 01388143692 was initiated on Friday, October 21, 1994 by Heather Cummings, holder of passport 00S5KMHJ. Any queries should be directed to ++218 434-595-1288 or elizabethholmes@holt.com.', 'annotations': {'entities': [(14, 41, 'IBAN_CODE'), (47, 58, 'BANK_NUMBER'), (76, 100, 'DATE_TIME'), (104, 120, 'PERSON'), (141, 149, 'PASSPORT'), (185, 203, 'PHONE_NUMBER'), (207, 231, 'EMAIL_ADDRESS')]}}\n",
            "{'text': 'Robert Smith confirmed a payment using card 3526 6583 2649 3032 on 28/05/2014 03:50 PM.', 'annotations': {'entities': [(0, 12, 'PERSON'), (44, 63, 'CREDIT_CARD'), (67, 86, 'DATE_TIME')]}}\n",
            "{'text': \"Update received from Ms. Tabitha Gonzales: Change of address to 0586 Gates Spring Suite 938, Port Caitlin, NH 89879 and phone to 266-476-5164 was noted. New driver's license OH-QW83603 was issued and sent to robertsonmatthew@verizon.net.\", 'annotations': {'entities': [(21, 41, 'PERSON'), (64, 115, 'LOCATION'), (129, 141, 'PHONE_NUMBER'), (174, 184, 'DRIVER_LICENSE'), (208, 236, 'EMAIL_ADDRESS')]}}\n",
            "{'text': \"Michael Oneill's ITIN 995-72-3006 and driver's license HI-EY27811384 were used to process a transaction on 23-Mar-1990 06:00.\", 'annotations': {'entities': [(0, 14, 'PERSON'), (22, 33, 'ITIN'), (55, 68, 'DRIVER_LICENSE'), (107, 124, 'DATE_TIME')]}}\n",
            "{'text': \"A parcel for Paige H. Soto is awaiting pickup at 50393 Thomas Summit Suite 722, Lake Erinborough, GA 93890. Driver's license NM-335120 and SSN 465-24-4129 will be needed for verification.\", 'annotations': {'entities': [(13, 26, 'PERSON'), (49, 106, 'LOCATION'), (125, 134, 'DRIVER_LICENSE'), (143, 154, 'SSN')]}}\n",
            "{'text': 'Dr. Ruth Roman with ITIN 978-74-8834 booked a consultation on 2013-12-19 15:25:10. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details 0970-3138-401 were verified for the appointment.', 'annotations': {'entities': [(0, 14, 'PERSON'), (25, 36, 'ITIN'), (62, 81, 'DATE_TIME'), (94, 133, 'IP_ADDRESS'), (151, 164, 'BANK_NUMBER')]}}\n",
            "{'text': \"Notice for Jason Gonzalez: Your recent application using SSN 210-50-8680 and driver's license MS-F976150 has been approved. Please confirm your email wmontgomery@wells.biz.\", 'annotations': {'entities': [(11, 25, 'PERSON'), (61, 72, 'SSN'), (94, 104, 'DRIVER_LICENSE'), (150, 171, 'EMAIL_ADDRESS')]}}\n",
            "{'text': \"New login to https://app.becker.org.co.uk/login?q=searchTerm#comments by William F. Hall using ITIN 998-75-3250 from 38.18.251.235 on 20/10/2013 11:48 PM. If this wasn't you, please notify us immediately at qreeves@santos-williams.com.\", 'annotations': {'entities': [(13, 69, 'URL'), (73, 88, 'PERSON'), (100, 111, 'ITIN'), (117, 130, 'IP_ADDRESS'), (134, 153, 'DATE_TIME'), (207, 234, 'EMAIL_ADDRESS')]}}\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for any overlap in annotations"
      ],
      "metadata": {
        "id": "x2JCafONlxKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_annotations_in_dataset(annotated_dataset_sequential):\n",
        "    # Iterate through each record in the annotated dataset\n",
        "    for record in annotated_dataset_sequential:\n",
        "        # Extract the entities (start, end, label) from each record's annotations\n",
        "        entities = record[\"annotations\"][\"entities\"]\n",
        "        # Sort the entities by their start index to compare consecutive entities\n",
        "        entities.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Check for overlap between consecutive entities\n",
        "        for i in range(len(entities) - 1):\n",
        "            current_entity = entities[i]\n",
        "            next_entity = entities[i + 1]\n",
        "            # Assert that there is no overlap: the current entity's end index must be\n",
        "            # less than or equal to the next entity's start index.\n",
        "            assert current_entity[1] <= next_entity[0], f\"Overlap found between {current_entity} and {next_entity}\"\n",
        "\n",
        "# Execute the verification function to check for overlapping annotations\n",
        "try:\n",
        "    verify_annotations_in_dataset(annotated_dataset_sequential)\n",
        "    print(\"No overlaps found in annotations.\")\n",
        "except AssertionError as e:\n",
        "    # If an overlap is found, print the details\n",
        "    print(f\"Validation error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fGj-dBilqi",
        "outputId": "564bcaf9-58af-451c-b3e4-a07967d0057c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No overlaps found in annotations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download a public dataset like AG_News"
      ],
      "metadata": {
        "id": "ZafVGSy4l6Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load ag_news dataset\n",
        "ag_news_dataset = load_dataset('ag_news', split='train')\n",
        "\n",
        "# Sample a subset of the ag_news dataset for integration\n",
        "ag_news_sample = ag_news_dataset.select(range(10000))\n",
        "\n",
        "# Convert ag_news samples to the same format as the synthetic dataset\n",
        "ag_news_texts = [{\"text\": sample['text'], \"annotations\": {\"entities\": []}} for sample in ag_news_sample]\n",
        "\n",
        "# for record in ag_news_texts[:10]:\n",
        "#    print(record)\n",
        "\n",
        "# Merge the synthetic dataset with the ag_news samples\n",
        "combined_dataset = annotated_dataset_sequential + ag_news_texts\n",
        "\n",
        "# Convert the combined dataset to spaCy format\n",
        "spacy_combined_training_data = convert_to_spacy_format(combined_dataset)\n",
        "print(len(spacy_combined_training_data))\n",
        "\n",
        "# Print the first few lines of the combined dataset\n",
        "for record in spacy_combined_training_data[:10]:\n",
        "    print(record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOV9-BjgefHW",
        "outputId": "437001d0-4ed5-4f26-ddc8-bd9e58cd0a7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "20000\n",
            "('User Katie Cook MD, with ITIN 999-77-1709, accessed https://mail.dean-richards.org.edu on 1990-03-13 02:10:13 from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to 025553533725, contact 2756939473.', {'entities': [(5, 18, 'PERSON'), (30, 41, 'ITIN'), (52, 86, 'URL'), (90, 109, 'DATE_TIME'), (118, 157, 'IP_ADDRESS'), (190, 202, 'BANK_NUMBER'), (212, 222, 'PHONE_NUMBER')]})\n",
            "('Nicole B. Garcia confirmed their attendance for the webinar on 19/11/2007 08:26 AM at Lake Julieville, Croatia. Registration details: SSN 115-76-4581, contact ++855 5366764295, and nationality Colombia.', {'entities': [(0, 16, 'PERSON'), (63, 82, 'DATE_TIME'), (86, 110, 'LOCATION'), (138, 149, 'SSN'), (159, 175, 'PHONE_NUMBER'), (193, 201, 'NRP')]})\n",
            "('A transfer to GB22 GOHM 0444 6516 0413 50 from 01388143692 was initiated on Friday, October 21, 1994 by Heather Cummings, holder of passport 00S5KMHJ. Any queries should be directed to ++218 434-595-1288 or elizabethholmes@holt.com.', {'entities': [(14, 41, 'IBAN_CODE'), (47, 58, 'BANK_NUMBER'), (76, 100, 'DATE_TIME'), (104, 120, 'PERSON'), (141, 149, 'PASSPORT'), (185, 203, 'PHONE_NUMBER'), (207, 231, 'EMAIL_ADDRESS')]})\n",
            "('Robert Smith confirmed a payment using card 3526 6583 2649 3032 on 28/05/2014 03:50 PM.', {'entities': [(0, 12, 'PERSON'), (44, 63, 'CREDIT_CARD'), (67, 86, 'DATE_TIME')]})\n",
            "(\"Update received from Ms. Tabitha Gonzales: Change of address to 0586 Gates Spring Suite 938, Port Caitlin, NH 89879 and phone to 266-476-5164 was noted. New driver's license OH-QW83603 was issued and sent to robertsonmatthew@verizon.net.\", {'entities': [(21, 41, 'PERSON'), (64, 115, 'LOCATION'), (129, 141, 'PHONE_NUMBER'), (174, 184, 'DRIVER_LICENSE'), (208, 236, 'EMAIL_ADDRESS')]})\n",
            "(\"Michael Oneill's ITIN 995-72-3006 and driver's license HI-EY27811384 were used to process a transaction on 23-Mar-1990 06:00.\", {'entities': [(0, 14, 'PERSON'), (22, 33, 'ITIN'), (55, 68, 'DRIVER_LICENSE'), (107, 124, 'DATE_TIME')]})\n",
            "(\"A parcel for Paige H. Soto is awaiting pickup at 50393 Thomas Summit Suite 722, Lake Erinborough, GA 93890. Driver's license NM-335120 and SSN 465-24-4129 will be needed for verification.\", {'entities': [(13, 26, 'PERSON'), (49, 106, 'LOCATION'), (125, 134, 'DRIVER_LICENSE'), (143, 154, 'SSN')]})\n",
            "('Dr. Ruth Roman with ITIN 978-74-8834 booked a consultation on 2013-12-19 15:25:10. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details 0970-3138-401 were verified for the appointment.', {'entities': [(0, 14, 'PERSON'), (25, 36, 'ITIN'), (62, 81, 'DATE_TIME'), (94, 133, 'IP_ADDRESS'), (151, 164, 'BANK_NUMBER')]})\n",
            "(\"Notice for Jason Gonzalez: Your recent application using SSN 210-50-8680 and driver's license MS-F976150 has been approved. Please confirm your email wmontgomery@wells.biz.\", {'entities': [(11, 25, 'PERSON'), (61, 72, 'SSN'), (94, 104, 'DRIVER_LICENSE'), (150, 171, 'EMAIL_ADDRESS')]})\n",
            "(\"New login to https://app.becker.org.co.uk/login?q=searchTerm#comments by William F. Hall using ITIN 998-75-3250 from 38.18.251.235 on 20/10/2013 11:48 PM. If this wasn't you, please notify us immediately at qreeves@santos-williams.com.\", {'entities': [(13, 69, 'URL'), (73, 88, 'PERSON'), (100, 111, 'ITIN'), (117, 130, 'IP_ADDRESS'), (134, 153, 'DATE_TIME'), (207, 234, 'EMAIL_ADDRESS')]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess & clean the combined dataset"
      ],
      "metadata": {
        "id": "ALryCTCTnYBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function to clean text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
        "    #text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    #text = re.sub(r'\\@\\w+', '', text)  # Remove mentions\n",
        "    #text = re.sub(r'\\#\\w+', '', text)  # Remove hashtags\n",
        "    #text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the combined dataset\n",
        "cleaned_spacy_combined_training_data = [\n",
        "    (preprocess_text(record[0]), record[1]) for record in spacy_combined_training_data\n",
        "]\n",
        "\n",
        "# Print the first few lines of the cleaned combined dataset\n",
        "for record in cleaned_spacy_combined_training_data[:10]:\n",
        "    print(record)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmA_DhGshhI_",
        "outputId": "933ad6a6-c56a-4a08-f3cb-ba6bae4599e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('User Katie Cook MD, with ITIN 999-77-1709, accessed https://mail.dean-richards.org.edu on 1990-03-13 02:10:13 from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to 025553533725, contact 2756939473.', {'entities': [(5, 18, 'PERSON'), (30, 41, 'ITIN'), (52, 86, 'URL'), (90, 109, 'DATE_TIME'), (118, 157, 'IP_ADDRESS'), (190, 202, 'BANK_NUMBER'), (212, 222, 'PHONE_NUMBER')]})\n",
            "('Nicole B. Garcia confirmed their attendance for the webinar on 19/11/2007 08:26 AM at Lake Julieville, Croatia. Registration details: SSN 115-76-4581, contact ++855 5366764295, and nationality Colombia.', {'entities': [(0, 16, 'PERSON'), (63, 82, 'DATE_TIME'), (86, 110, 'LOCATION'), (138, 149, 'SSN'), (159, 175, 'PHONE_NUMBER'), (193, 201, 'NRP')]})\n",
            "('A transfer to GB22 GOHM 0444 6516 0413 50 from 01388143692 was initiated on Friday, October 21, 1994 by Heather Cummings, holder of passport 00S5KMHJ. Any queries should be directed to ++218 434-595-1288 or elizabethholmes@holt.com.', {'entities': [(14, 41, 'IBAN_CODE'), (47, 58, 'BANK_NUMBER'), (76, 100, 'DATE_TIME'), (104, 120, 'PERSON'), (141, 149, 'PASSPORT'), (185, 203, 'PHONE_NUMBER'), (207, 231, 'EMAIL_ADDRESS')]})\n",
            "('Robert Smith confirmed a payment using card 3526 6583 2649 3032 on 28/05/2014 03:50 PM.', {'entities': [(0, 12, 'PERSON'), (44, 63, 'CREDIT_CARD'), (67, 86, 'DATE_TIME')]})\n",
            "(\"Update received from Ms. Tabitha Gonzales: Change of address to 0586 Gates Spring Suite 938, Port Caitlin, NH 89879 and phone to 266-476-5164 was noted. New driver's license OH-QW83603 was issued and sent to robertsonmatthew@verizon.net.\", {'entities': [(21, 41, 'PERSON'), (64, 115, 'LOCATION'), (129, 141, 'PHONE_NUMBER'), (174, 184, 'DRIVER_LICENSE'), (208, 236, 'EMAIL_ADDRESS')]})\n",
            "(\"Michael Oneill's ITIN 995-72-3006 and driver's license HI-EY27811384 were used to process a transaction on 23-Mar-1990 06:00.\", {'entities': [(0, 14, 'PERSON'), (22, 33, 'ITIN'), (55, 68, 'DRIVER_LICENSE'), (107, 124, 'DATE_TIME')]})\n",
            "(\"A parcel for Paige H. Soto is awaiting pickup at 50393 Thomas Summit Suite 722, Lake Erinborough, GA 93890. Driver's license NM-335120 and SSN 465-24-4129 will be needed for verification.\", {'entities': [(13, 26, 'PERSON'), (49, 106, 'LOCATION'), (125, 134, 'DRIVER_LICENSE'), (143, 154, 'SSN')]})\n",
            "('Dr. Ruth Roman with ITIN 978-74-8834 booked a consultation on 2013-12-19 15:25:10. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details 0970-3138-401 were verified for the appointment.', {'entities': [(0, 14, 'PERSON'), (25, 36, 'ITIN'), (62, 81, 'DATE_TIME'), (94, 133, 'IP_ADDRESS'), (151, 164, 'BANK_NUMBER')]})\n",
            "(\"Notice for Jason Gonzalez: Your recent application using SSN 210-50-8680 and driver's license MS-F976150 has been approved. Please confirm your email wmontgomery@wells.biz.\", {'entities': [(11, 25, 'PERSON'), (61, 72, 'SSN'), (94, 104, 'DRIVER_LICENSE'), (150, 171, 'EMAIL_ADDRESS')]})\n",
            "(\"New login to https://app.becker.org.co.uk/login?q=searchTerm#comments by William F. Hall using ITIN 998-75-3250 from 38.18.251.235 on 20/10/2013 11:48 PM. If this wasn't you, please notify us immediately at qreeves@santos-williams.com.\", {'entities': [(13, 69, 'URL'), (73, 88, 'PERSON'), (100, 111, 'ITIN'), (117, 130, 'IP_ADDRESS'), (134, 153, 'DATE_TIME'), (207, 234, 'EMAIL_ADDRESS')]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PII Detection Using Traditional Methods (Regex) and spaCy's NER"
      ],
      "metadata": {
        "id": "MzFywGN0wauk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PII Detection using traditional methods like Regex or open source NER\n",
        "\n",
        "# Installing Required Libraries\n",
        "!pip install DLNValidation\n",
        "!pip install spacy-langdetect\n",
        "!pip install py3DNS\n",
        "!pip install validate-email-address\n",
        "!pip install email-validator\n",
        "!pip install python-stdnum\n",
        "!pip install spacy-transformers\n",
        "!pip install torch\n",
        "!python -m spacy download en_core_web_trf\n",
        "!pip install tldextract\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from spacy.language import Language\n",
        "from spacy_langdetect import LanguageDetector\n",
        "from validate_email_address import validate_email\n",
        "from dlnvalidation import is_valid\n",
        "from datetime import datetime\n",
        "from stdnum import luhn\n",
        "from stdnum import iban\n",
        "from stdnum.iso7064 import mod_97_10\n",
        "import calendar\n",
        "from dateutil.parser import parse\n",
        "\n",
        "# Loading spaCy's Transformer-based Model and Language Detector\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "# Define regex patterns for different PII types\n",
        "regex_patterns = {\n",
        "    'CREDIT_CARD': r'\\b(?:\\d[ -]*?){13,19}\\b',\n",
        "    'DATE_TIME': r'\\b(?:\\d{1,4}[\\/\\-]\\d{1,2}[\\/\\-]\\d{1,4}|\\d{1,2}:\\d{2}(?::\\d{2})?(?:\\s?[AP]M)?)\\b',\n",
        "    'EMAIL_ADDRESS': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
        "    'IBAN_CODE': r'\\b[A-Z]{2}\\d{2}[A-Z0-9]{4}\\d{7}([A-Z0-9]?){0,16}\\b',\n",
        "    'IP_ADDRESS': r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b',\n",
        "    'PHONE_NUMBER': r'\\b(?:\\+?[\\d\\s]{3,}\\)?[\\d\\s-]{6,}\\d)\\b',\n",
        "    'URL': r'\\b(?:https?://)?[^\\s/$.?#].[^\\s]*\\.\\b(?:com|org|net|edu|gov|mil|co|io|ai|[a-z]{2})\\b[^\\s]*',\n",
        "    'BANK_NUMBER': r'\\b\\d{8,17}\\b',\n",
        "    'DRIVER_LICENSE': r'\\b[A-Z]{1,2}-?\\d{5,9}\\b',\n",
        "    'ITIN': r'\\b9\\d{2}-?(?:7|8)\\d-?\\d{4}\\b',\n",
        "    'PASSPORT': r'\\b\\d{9}\\b',\n",
        "    'SSN': r'\\b\\d{3}-?\\d{2}-?\\d{4}\\b',\n",
        "}\n",
        "\n",
        "# Define checksum validators\n",
        "def validate_credit_card(number):\n",
        "    return luhn.is_valid(number)\n",
        "\n",
        "def validate_iban(number):\n",
        "    return iban.is_valid(number)\n",
        "\n",
        "def validate_ip_address(ip):\n",
        "    # This will only check the format, not the actual validity of the IP\n",
        "    try:\n",
        "        if ':' in ip:  # This is a basic check for IPv6 format\n",
        "            return True  # We assume IPv6 is valid as we don't have a checksum method\n",
        "        else:\n",
        "            parts = ip.split('.')\n",
        "            return len(parts) == 4 and all(0 <= int(part) < 256 for part in parts)\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "def get_lang_detector(nlp, name):\n",
        "    return LanguageDetector()\n",
        "\n",
        "def validate_dln(number) :\n",
        "    # implement is valid for every state\n",
        "    # List of US state codes to check the DLN against\n",
        "    state_codes = [\n",
        "        'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA',\n",
        "        'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD',\n",
        "        'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ',\n",
        "        'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC',\n",
        "        'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
        "    ]\n",
        "\n",
        "    for state_code in state_codes:\n",
        "        if is_valid(number, state_code):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def detect_and_redact(text):\n",
        "    # Check for IP addresses, IBAN codes, credit card numbers, and US ITIN with checksum\n",
        "    for entity, pattern in regex_patterns.items():\n",
        "        for match in re.finditer(pattern, text):\n",
        "            if entity == 'CREDIT_CARD' and validate_credit_card(match.group()):\n",
        "                text = text.replace(match.group(), '[REDACTED_CRED]')\n",
        "            elif entity == 'IBAN_CODE' and validate_iban(match.group()):\n",
        "                text = text.replace(match.group(), '[REDACTED_IBAN]')\n",
        "            elif entity == 'EMAIL_ADDRESS' and validate_email(match.group(), verify=True):\n",
        "                text = text.replace(match.group(), '[REDACTED]')\n",
        "            elif entity in ['IP_ADDRESS', 'ITIN', 'PASSPORT', 'SSN', 'URL']:\n",
        "                text = text.replace(match.group(), '[REDACTED]')\n",
        "            elif entity == 'DRIVER_LICENSE' and validate_dln(match.group()):\n",
        "                text = text.replace(match.group(), '[REDACTED]')\n",
        "            elif entity == 'DATE_TIME':\n",
        "                try:\n",
        "                    # This will raise an exception if it's not a real date/time\n",
        "                    if parse(match.group(), fuzzy=False):\n",
        "                        text = text.replace(match.group(), '[REDACTED]')\n",
        "                except ValueError:\n",
        "                    continue\n",
        "            elif entity == 'URL':\n",
        "                extracted = tldextract.extract(matched_text)\n",
        "                if not extracted.suffix:  # If there's no recognizable TLD\n",
        "                    continue  # Consider adding a specific action here, like redacting or logging\n",
        "                else:\n",
        "                    text = text.replace(matched_text, '[REDACTED]')\n",
        "            else:\n",
        "                text = text.replace(match .group(), '[REDACTED_CUSTOM]')\n",
        "\n",
        "    # Detect and redact named entities using spaCy\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in ['PERSON', 'GPE', 'ORG', 'NORP','LOC', 'DATE', 'TIME']:\n",
        "            text = text.replace(ent.text, '[REDACTED_NER]')\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "example_text = \"\"\"\n",
        "    Sushil's email is 2022cs04045@wilp.bits-pilani.ac.in and his credit card number is 4874940012002902.\n",
        "    His IP is 192.168.1.1 and his IBAN is GB33BUKB20201555555555. He lives in Bangalore in India. It is the 22nd Jan and 4pm. His religion is Hindu and he believes in Hinduism.\n",
        "    He is from India. His email website is yahoo.co.in and https://in.search.yahoo.com/?fr2=inr His driving license is G454666\"\"\"\n",
        "\n",
        "redacted_example = detect_and_redact(example_text)\n",
        "print(redacted_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAmLnZ-LSoWQ",
        "outputId": "1d6a269c-ec7c-43ec-b14b-f25834367b40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: DLNValidation in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: spacy-langdetect in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from spacy-langdetect) (7.4.4)\n",
            "Requirement already satisfied: langdetect==1.0.7 in /usr/local/lib/python3.10/dist-packages (from spacy-langdetect) (1.0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.7->spacy-langdetect) (1.16.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->spacy-langdetect) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->spacy-langdetect) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->spacy-langdetect) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->spacy-langdetect) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->spacy-langdetect) (2.0.1)\n",
            "Requirement already satisfied: py3DNS in /usr/local/lib/python3.10/dist-packages (4.0.2)\n",
            "Requirement already satisfied: validate-email-address in /usr/local/lib/python3.10/dist-packages (1)\n",
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator) (3.10)\n",
            "Requirement already satisfied: python-stdnum in /usr/local/lib/python3.10/dist-packages (1.20)\n",
            "Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (3.7.6)\n",
            "Requirement already satisfied: transformers<4.37.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (4.36.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.4.8)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (1.26.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.4.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "Collecting en-core-web-trf==3.7.3\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.7.3) (3.7.6)\n",
            "Requirement already satisfied: spacy-curated-transformers<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.7.3) (0.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.26.4)\n",
            "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.1.1)\n",
            "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (0.0.9)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.4.0+cu121)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.10/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2024.9.11)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.23.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2024.6.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (5.1.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.32.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(filelike, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(self._mixed_precision):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    [REDACTED_NER]'s email is [REDACTED] and his credit card number is [REDACTED_CUSTOM].\n",
            "    His IP is [REDACTED] and his IBAN is [REDACTED_IBAN]. He lives in [REDACTED_NER] in [REDACTED_NER]. It is [REDACTED_NER]. His religion is [REDACTED_NER] and he believes in [REDACTED_NER]ism.\n",
            "    He is from [REDACTED_NER]. His email website is [REDACTED] and [REDACTED] His driving license is [REDACTED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply redaction to synthetic dataset"
      ],
      "metadata": {
        "id": "-PzNqK_V3Jif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mLM9zKvO0FG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply redaction to each item in the dataset\n",
        "redacted_texts = []\n",
        "sample_set=spacy_training_data[0:100]\n",
        "for text, annot_dict in sample_set:\n",
        "    annotations = annot_dict['entities']  # Extracting the 'entities' from the annotations dictionary\n",
        "  #  print (\"annotations:\",annotations)\n",
        "  #  print (\"text\",text)\n",
        "    redacted_text = detect_and_redact(text)\n",
        "    redacted_texts.append(redacted_text)\n",
        "print(len(spacy_training_data))\n",
        "\n",
        "# Example output\n",
        "for original, redacted in zip(sample_set, redacted_texts[:10]):\n",
        "    print(\"Original:\", original[0]) # Print the original, unredacted text\n",
        "    print(\"Redacted:\", redacted)    # Print the redacted version of the text\n",
        "    print(\"-------\")                # Separator between outputs\n",
        "\n",
        "len(redacted_texts)"
      ],
      "metadata": {
        "id": "ScS2ReCbYMjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97639eeb-dcf1-4f04-b77a-ea8066b5ba81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "Original: User Katie Cook MD, with ITIN 999-77-1709, accessed https://mail.dean-richards.org.edu on 1990-03-13 02:10:13 from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to 025553533725, contact 2756939473.\n",
            "Redacted: User [REDACTED_NER], with ITIN[REDACTED_CUSTOM], accessed [REDACTED] on [REDACTED] [REDACTED] from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to[REDACTED_CUSTOM], contact[REDACTED_CUSTOM].\n",
            "-------\n",
            "Original: Nicole B. Garcia confirmed their attendance for the webinar on 19/11/2007 08:26 AM at Lake Julieville, Croatia. Registration details: SSN 115-76-4581, contact ++855 5366764295, and nationality Colombia.\n",
            "Redacted: [REDACTED_NER] confirmed their attendance for the webinar on [REDACTED] [REDACTED] at [REDACTED_NER], [REDACTED_NER]. Registration details: SSN[REDACTED_CUSTOM], contact ++[REDACTED_CUSTOM], and nationality [REDACTED_NER].\n",
            "-------\n",
            "Original: A transfer to GB22 GOHM 0444 6516 0413 50 from 01388143692 was initiated on Friday, October 21, 1994 by Heather Cummings, holder of passport 00S5KMHJ. Any queries should be directed to ++218 434-595-1288 or elizabethholmes@holt.com.\n",
            "Redacted: A transfer to GB22 GOHM [REDACTED_CUSTOM] from[REDACTED_CUSTOM] was initiated on [REDACTED_NER] by [REDACTED_NER], holder of passport 00S5KMHJ. Any queries should be directed to ++[REDACTED_CUSTOM] or [REDACTED_CUSTOM].\n",
            "-------\n",
            "Original: Robert Smith confirmed a payment using card 3526 6583 2649 3032 on 28/05/2014 03:50 PM.\n",
            "Redacted: [REDACTED_NER] confirmed a payment using card [REDACTED_CUSTOM] on [REDACTED] [REDACTED].\n",
            "-------\n",
            "Original: Update received from Ms. Tabitha Gonzales: Change of address to 0586 Gates Spring Suite 938, Port Caitlin, NH 89879 and phone to 266-476-5164 was noted. New driver's license OH-QW83603 was issued and sent to robertsonmatthew@verizon.net.\n",
            "Redacted: Update received from Ms. [REDACTED_NER]: Change of address to 0586 Gates Spring Suite 938, [REDACTED_NER], [REDACTED_NER] 89879 and phone to[REDACTED_CUSTOM] was noted. New driver's license OH-[REDACTED] was issued and sent to [REDACTED].\n",
            "-------\n",
            "Original: Michael Oneill's ITIN 995-72-3006 and driver's license HI-EY27811384 were used to process a transaction on 23-Mar-1990 06:00.\n",
            "Redacted: [REDACTED_NER] ITIN[REDACTED_CUSTOM] and driver's license HI-[REDACTED] were used to process a transaction on [REDACTED_NER]REDACTED].\n",
            "-------\n",
            "Original: A parcel for Paige H. Soto is awaiting pickup at 50393 Thomas Summit Suite 722, Lake Erinborough, GA 93890. Driver's license NM-335120 and SSN 465-24-4129 will be needed for verification.\n",
            "Redacted: A parcel for [REDACTED_NER] is awaiting pickup at 50393 Thomas Summit Suite 722, [REDACTED_NER], [REDACTED_NER] 93890. Driver's license [REDACTED_CUSTOM] and SSN[REDACTED_CUSTOM] will be needed for verification.\n",
            "-------\n",
            "Original: Dr. Ruth Roman with ITIN 978-74-8834 booked a consultation on 2013-12-19 15:25:10. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details 0970-3138-401 were verified for the appointment.\n",
            "Redacted: Dr. [REDACTED_NER] with ITIN[REDACTED_CUSTOM] booked a consultation on [REDACTED] [REDACTED]. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details[REDACTED_CUSTOM] were verified for the appointment.\n",
            "-------\n",
            "Original: Notice for Jason Gonzalez: Your recent application using SSN 210-50-8680 and driver's license MS-F976150 has been approved. Please confirm your email wmontgomery@wells.biz.\n",
            "Redacted: Notice for [REDACTED_NER]: Your recent application using SSN[REDACTED_CUSTOM] and driver's license MS-[REDACTED] has been approved. Please confirm your email [REDACTED_CUSTOM].\n",
            "-------\n",
            "Original: New login to https://app.becker.org.co.uk/login?q=searchTerm#comments by William F. Hall using ITIN 998-75-3250 from 38.18.251.235 on 20/10/2013 11:48 PM. If this wasn't you, please notify us immediately at qreeves@santos-williams.com.\n",
            "Redacted: New login to [REDACTED] by [REDACTED_NER] using ITIN[REDACTED_CUSTOM] from [REDACTED] on [REDACTED] [REDACTED]. If this wasn't you, please notify us immediately at [REDACTED_CUSTOM].\n",
            "-------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the performance of the PII redaction process\n"
      ],
      "metadata": {
        "id": "qJsRBvZO74Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the PII redaction process by calculating key metrics: precision, recall, and the F1 score.\n",
        "print(len(sample_set))\n",
        "\n",
        "def count_unredacted_entities(original_text, redacted_text, entities):\n",
        "\n",
        "    \"\"\"\n",
        "    This function counts the number of entities that were not redacted in the redacted text.\n",
        "\n",
        "    Parameters:\n",
        "    - original_text: The unredacted, original text.\n",
        "    - redacted_text: The text that has been processed and redacted.\n",
        "    - entities: List of entity annotations with start and end positions.\n",
        "\n",
        "    Returns:\n",
        "    - unredacted_count: Number of entities that were not redacted and still present in the redacted text.\n",
        "    \"\"\"\n",
        "\n",
        "    unredacted_count = 0\n",
        "    for start, end, _ in entities:\n",
        "        entity_text = original_text[start:end]\n",
        "        # Check if the entity text is still present in the redacted text\n",
        "        if entity_text in redacted_text:\n",
        "            unredacted_count += 1\n",
        "    return unredacted_count\n",
        "\n",
        "def calculate_performance_metrics(annotated_data, redacted_texts):\n",
        "    \"\"\"\n",
        "    This function calculates the key performance metrics (precision, recall, F1 score)\n",
        "    for the PII redaction process based on the original and redacted texts.\n",
        "\n",
        "    Parameters:\n",
        "    - annotated_data: The original dataset with annotations (list of (text, annotations) pairs).\n",
        "    - redacted_texts: The list of texts after redaction (processed texts).\n",
        "\n",
        "    Returns:\n",
        "    - precision: The precision score, which measures the percentage of correctly redacted entities out of all redactions.\n",
        "    - recall: The recall score, which measures the percentage of entities that should have been redacted but were missed.\n",
        "    - f1_score: The harmonic mean of precision and recall, providing a balanced performance measure.\n",
        "    \"\"\"\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    for ((text, annotation), redacted_text) in zip(annotated_data, redacted_texts):\n",
        "        entities = annotation['entities']\n",
        "        redacted_count = redacted_text.count('[REDACTED]')\n",
        "\n",
        "        TP += len(entities) - count_unredacted_entities(text, redacted_text, entities)  # Adjusted TP calculation\n",
        "        FN += count_unredacted_entities(text, redacted_text, entities)  # Now actually calculates FNs\n",
        "        FP += max(0, redacted_count - len(entities))  # Extra redactions are considered FPs\n",
        "\n",
        "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "    # Print results and the list of unredacted entities\n",
        "    print(f\"\\nTrue Positives (Correct Redactions): {TP}\")\n",
        "    print(f\"False Positives (Over-redactions): {FP}\")\n",
        "    print(f\"False Negatives (Missed Redactions): {FN}\\n\")\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "# Example usage\n",
        "precision, recall, f1_score = calculate_performance_metrics(sample_set[0:1023], redacted_texts)\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1_score:.2f}\")\n",
        "\n",
        "# print(len(spacy_training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF3IxQIE0pNs",
        "outputId": "f3cba24d-c6ae-46fa-9849-bce3a9486fb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "\n",
            "True Positives (Correct Redactions): 451\n",
            "False Positives (Over-redactions): 0\n",
            "False Negatives (Missed Redactions): 44\n",
            "\n",
            "Precision: 1.00, Recall: 0.91, F1 Score: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning en_core_web_trf Model using synthetic PII dataset\n"
      ],
      "metadata": {
        "id": "x-ZyjkEYM3UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetuning Custom Model using Spacy2.0\n",
        "import os\n",
        "import spacy\n",
        "from spacy.training import Example\n",
        "import random\n",
        "sample_set=spacy_training_data[0:10000]\n",
        "#nlp = spacy.load(\"en\")\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "existing_entities = nlp.get_pipe(\"ner\").labels\n",
        "print(existing_entities)\n",
        "new_entities = [\"CREDIT_CARD\", \"SSN\",\"EMAIL_ADDRESS\", \"IP_ADDRESS\",'PHONE_NUMBER','URL','BANK_NUMBER','DRIVER_LICENSE','ITIN','PASSPORT']\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "for entity in new_entities:\n",
        "    ner.add_label(entity)\n",
        "\n",
        "TRAIN_DATA = sample_set[0:100]\n",
        "print (len(TRAIN_DATA))\n",
        "#print (TRAIN_DATA)\n",
        "# Assuming nlp is your loaded or created spaCy model with the NER component\n",
        "# Make sure NUM_EPOCHS is defined, e.g., NUM_EPOCHS = 10\n",
        "# Shuffle the training data\n",
        "random.shuffle(TRAIN_DATA)\n",
        "\n",
        "# Begin training\n",
        "optimizer = nlp.resume_training()\n",
        "\n",
        "# Number of epochs to train the model\n",
        "NUM_EPOCHS = 2\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "\n",
        "    # Train the model on each example\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp.make_doc(text)\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "        nlp.update([example], drop=0.5, losses=losses)\n",
        "\n",
        "    print(f\"Losses at epoch {epoch}: {losses}\")\n",
        "\n",
        "# Save the trained model to a directory\n",
        "output_dir = \"./trained_model\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "nlp.to_disk(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n",
        "\n",
        "# Test the model immediately after training\n",
        "#test_text = \"Updated their emergency contact details to +919451514358. The security question linked to SSN 559-33-5905 and bank account 4854980002002907 was also updated.\"\n",
        "test_text = \"Customer Mr. Sushil Kumar requested an account statement for 873815548953 to be mailed to Delhi. For further assistance, reach out to 2022cs04045@wilp.bits-pilani.ac.in or 988.654.4600.\"\n",
        "\n",
        "doc = nlp(test_text)\n",
        "if not doc.ents:\n",
        "    print(\"No entities detected immediately after training.\")\n",
        "else:\n",
        "    for ent in doc.ents:\n",
        "        print(f\"Immediately after training: {ent.text} - {ent.label_}\")\n",
        "\n",
        "# Load the saved model from disk\n",
        "nlp_updated = spacy.load(output_dir)\n",
        "\n",
        "# Test the model after loading it\n",
        "doc_updated = nlp_updated(test_text)\n",
        "if not doc_updated.ents:\n",
        "    print(\"No entities detected after loading the model.\")\n",
        "else:\n",
        "    for ent in doc_updated.ents:\n",
        "        print(f\"After loading the model: {ent.text} - {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPmltbNB0v7y",
        "outputId": "3cd018b5-cc92-4caf-e6dd-9ef6a61b45cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n",
            "500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"A transfer to GB98 GGTU 6272 6232 2641 79 from 568...\" with entities \"[(14, 41, 'IBAN_CODE'), (47, 56, 'BANK_NUMBER'), (...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Our records show Dr. Brittany Dunn, nationality Co...\" with entities \"[(17, 34, 'PERSON'), (48, 57, 'NRP'), (97, 105, 'P...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"A transfer to GB57 HLPC 8555 0800 9063 57 from 946...\" with entities \"[(14, 41, 'IBAN_CODE'), (47, 60, 'BANK_NUMBER'), (...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses at epoch 0: {'transformer': 4320.009489893913, 'tagger': 0.0, 'parser': 0.0, 'ner': 5157.2391159887065}\n",
            "Losses at epoch 1: {'transformer': 4372.224582195282, 'tagger': 0.0, 'parser': 0.0, 'ner': 5154.860774141052}\n",
            "Model saved to ./trained_model\n",
            "Immediately after training: Kristen Murphy - PERSON\n",
            "Immediately after training: Sanchezton - ORG\n",
            "After loading the model: Kristen Murphy - PERSON\n",
            "After loading the model: Sanchezton - ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "from spacy.training import Example\n",
        "import random\n",
        "from transformers import AutoModel\n",
        "\n",
        "sample_set=spacy_training_data[0:10000]\n",
        "\n",
        "# Load the spaCy model. \"en_core_web_trf\" is a transformer-based model.\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "# Print the existing entities in the model to see what entities it recognizes (like PERSON, ORG, etc.).\n",
        "existing_entities = nlp.get_pipe(\"ner\").labels\n",
        "print(existing_entities)  # Outputs: ['PERSON', 'ORG', 'GPE', 'LOC', etc.]\n",
        "\n",
        "# We define new entities that we want to add to the existing model (related to PII like CREDIT_CARD, SSN, etc.).\n",
        "new_entities = [\"CREDIT_CARD\", \"SSN\", \"EMAIL_ADDRESS\", \"IP_ADDRESS\", 'PHONE_NUMBER', 'URL', 'BANK_NUMBER', 'DRIVER_LICENSE', 'ITIN', 'PASSPORT']\n",
        "\n",
        "# Get the Named Entity Recognizer (NER) pipe from the loaded model.\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add the new entities to the model.\n",
        "for entity in new_entities:\n",
        "    ner.add_label(entity)\n",
        "\n",
        "# Use a subset of the training data for finetuning the model.sample_set comes from the generated synthetic dataset.\n",
        "TRAIN_DATA = sample_set[0:100]  # Use the first 100 records for training.\n",
        "\n",
        "# print(len(TRAIN_DATA))  # Output: 100 (length of the training data)\n",
        "\n",
        "# Shuffle the training data to ensure randomness during training.\n",
        "random.shuffle(TRAIN_DATA)\n",
        "\n",
        "# Begin training the model.\n",
        "optimizer = nlp.resume_training()\n",
        "\n",
        "# Define the number of training epochs (how many times we want the model to go over the training data).\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "# Perform training for the defined number of epochs.\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    random.shuffle(TRAIN_DATA)  # Shuffle the data for each epoch.\n",
        "    losses = {}  # Dictionary to store the loss value after each update (indicates how well the model is doing).\n",
        "\n",
        "    # Iterate through the training examples and update the model.\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        # Create a spaCy document (doc) object from the input text.\n",
        "        doc = nlp.make_doc(text)\n",
        "\n",
        "        # Create an Example object from the text and its corresponding annotations (entities).\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "\n",
        "        # Update the model with the training example, and adjust the loss based on the performance.\n",
        "        nlp.update([example], drop=0.5, losses=losses)  # drop=0.5 randomly drops data to prevent overfitting.\n",
        "\n",
        "    # Print the loss after each epoch to monitor progress.\n",
        "    print(f\"Losses at epoch {epoch}: {losses}\")\n",
        "\n",
        "# Save the trained model to a specified directory.\n",
        "output_dir = \"./trained_model\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)  # Create the directory if it doesn't exist.\n",
        "\n",
        "nlp.to_disk(output_dir)  # Save the model to disk.\n",
        "print(f\"Model saved to {output_dir}\")\n",
        "\n",
        "# Test the model on a new text sample immediately after training.\n",
        "#test_text = \"Customer Dr. Kristen Murphy requested an account statement for 873815548953 to be mailed to Sanchezton. For further assistance, reach out to christina79@aguirre-hall.net or 673.556.4431.\"\n",
        "test_text = \"Customer Mr. Sushil Kumar requested an account statement for 873815548953 to be mailed to Delhi. For further assistance, reach out to 2022cs04045@wilp.bits-pilani.ac.in or 988.654.4600.\"\n",
        "\n",
        "doc = nlp(test_text)  # Create a spaCy doc object from the test text.\n",
        "\n",
        "# Check if any named entities are detected in the test text immediately after training.\n",
        "if not doc.ents:\n",
        "    print(\"No entities detected immediately after training.\")\n",
        "else:\n",
        "    # Print out all the detected entities and their corresponding labels.\n",
        "    for ent in doc.ents:\n",
        "        print(f\"Immediately after training: {ent.text} - {ent.label_}\")\n",
        "\n",
        "# Load the saved model from disk to ensure that the trained model can be correctly reloaded.\n",
        "# nlp_updated = spacy.load(output_dir)\n",
        "\n",
        "# Test the reloaded model on the same test text.\n",
        "# doc_updated = nlp_updated(test_text)\n",
        "# if not doc_updated.ents:\n",
        "#    print(\"No entities detected after loading the model.\")\n",
        "#else:\n",
        "#    # Print out all the detected entities from the reloaded model.\n",
        "#    for ent in doc_updated.ents:\n",
        "#        print(f\"After loading the model: {ent.text} - {ent.label_}\")\n",
        "\n",
        "# Count the number of parameters in the underlying transformer model (likely RoBERTa-base).\n",
        "model = AutoModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Calculate and print the total number of parameters in the model.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nTotal parameters in the underlying transformer model: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c5TfUnIChw7",
        "outputId": "c5feb7ee-a357-43ea-e730-a5b46d11784b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n",
            "Losses at epoch 0: {'transformer': 814.881168782711, 'tagger': 0.0, 'parser': 0.0, 'ner': 971.4823097121027}\n",
            "Losses at epoch 1: {'transformer': 810.3824676275253, 'tagger': 0.0, 'parser': 0.0, 'ner': 974.5425711042709}\n",
            "Model saved to ./trained_model\n",
            "Immediately after training: Sushil Kumar - PERSON\n",
            "Immediately after training: Delhi - GPE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total parameters in the underlying transformer model: 124645632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving and Loading Redacted Text Data and Sample Set in JSON Format"
      ],
      "metadata": {
        "id": "e2XavuB4Qyrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Write the list to a file\n",
        "with open('my_list_redacted.txt', 'w') as file:\n",
        "    json.dump(redacted_texts, file)\n",
        "\n",
        "# Read the list back from the file\n",
        "with open('my_list_redacted.txt', 'r') as file:\n",
        "    read_list = json.load(file)\n",
        "\n",
        "print(read_list)\n",
        "\n",
        "import json\n",
        "# Write the list to a file\n",
        "with open('my_list_sample.txt', 'w') as file:\n",
        "    json.dump(sample_set[0:1023], file)\n",
        "\n",
        "# Read the list back from the file\n",
        "with open('my_list_sample.txt', 'r') as file:\n",
        "    read_list = json.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbaWWBeFgaOR",
        "outputId": "7dd81e6b-36b1-43f1-92d9-b2c90cb7b09a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User [REDACTED_NER], with ITIN[REDACTED_CUSTOM], accessed [REDACTED] on [REDACTED] [REDACTED] from IP d6a4:f22f:5b78:1cc1:7ec5:5780:c840:1a16. For account support related to[REDACTED_CUSTOM], contact[REDACTED_CUSTOM].', '[REDACTED_NER] confirmed their attendance for the webinar on [REDACTED] [REDACTED] at [REDACTED_NER], [REDACTED_NER]. Registration details: SSN[REDACTED_CUSTOM], contact ++[REDACTED_CUSTOM], and nationality [REDACTED_NER].', 'A transfer to GB22 GOHM [REDACTED_CUSTOM] from[REDACTED_CUSTOM] was initiated on [REDACTED_NER] by [REDACTED_NER], holder of passport 00S5KMHJ. Any queries should be directed to ++[REDACTED_CUSTOM] or [REDACTED_CUSTOM].', '[REDACTED_NER] confirmed a payment using card [REDACTED_CUSTOM] on [REDACTED] [REDACTED].', \"Update received from Ms. [REDACTED_NER]: Change of address to 0586 Gates Spring Suite 938, [REDACTED_NER], [REDACTED_NER] 89879 and phone to[REDACTED_CUSTOM] was noted. New driver's license OH-[REDACTED] was issued and sent to [REDACTED].\", \"[REDACTED_NER] ITIN[REDACTED_CUSTOM] and driver's license HI-[REDACTED] were used to process a transaction on [REDACTED_NER]REDACTED].\", \"A parcel for [REDACTED_NER] is awaiting pickup at 50393 Thomas Summit Suite 722, [REDACTED_NER], [REDACTED_NER] 93890. Driver's license [REDACTED_CUSTOM] and SSN[REDACTED_CUSTOM] will be needed for verification.\", 'Dr. [REDACTED_NER] with ITIN[REDACTED_CUSTOM] booked a consultation on [REDACTED] [REDACTED]. IP address 57bf:8ae2:3dbd:b85d:9d3a:49bd:5684:2f46 and bank details[REDACTED_CUSTOM] were verified for the appointment.', \"Notice for [REDACTED_NER]: Your recent application using SSN[REDACTED_CUSTOM] and driver's license MS-[REDACTED] has been approved. Please confirm your email [REDACTED_CUSTOM].\", \"New login to [REDACTED] by [REDACTED_NER] using ITIN[REDACTED_CUSTOM] from [REDACTED] on [REDACTED] [REDACTED]. If this wasn't you, please notify us immediately at [REDACTED_CUSTOM].\", 'A transfer to [REDACTED_IBAN] from[REDACTED_CUSTOM] was initiated on [REDACTED_NER] [REDACTED_NER], holder of passport 8NYULG60W. Any queries should be directed to ++996 ([REDACTED_CUSTOM] or [REDACTED_CUSTOM].', 'Final notice for [REDACTED_NER]: Credit card [REDACTED_CRED] payment overdue as of [REDACTED_NER]REDACTED]. Access to account[REDACTED_CUSTOM] may be restricted. Contact [REDACTED].', '[REDACTED_NER] with ITIN[REDACTED_CUSTOM] booked a consultation on [REDACTED_NER] IP address [REDACTED] and bank details[REDACTED_CUSTOM] were verified for the appointment.', \"A request to update Ms. [REDACTED_NER]'s email [REDACTED_CUSTOM] was submitted on [REDACTED_NER]REDACTED]. Contact 946-723-8851x63842 for any issues.\", '[REDACTED_NER] requested a credit increase for card [REDACTED_CUSTOM] on [REDACTED] [REDACTED]. New terms sent to [REDACTED_CUSTOM]. For questions, contact 876-858-9081x7648.', '[REDACTED_NER] confirmed a payment using card[REDACTED_CUSTOM] on [REDACTED] [REDACTED].', 'Dr. [REDACTED_NER] confirmed a payment using card [REDACTED_CUSTOM] on [REDACTED_NER] [REDACTED].', 'During our regular audit on [REDACTED_NER]REDACTED], we verified the account[REDACTED_CUSTOM] and ITIN[REDACTED_CUSTOM] for [REDACTED_NER] against the national database [REDACTED_NER].', \"Alert: Unauthorized login attempt on Ms. [REDACTED_NER]'s account[REDACTED_CUSTOM] detected from IP [REDACTED] on [REDACTED_NER]\", 'Security update: [REDACTED_NER], your password for account[REDACTED_CUSTOM] was reset on [REDACTED] [REDACTED]. A notification was sent to [REDACTED] from 6621:4c39:172c:e65c:2e5b:c1d9:5ec1:eb6b.', '[REDACTED_NER] appointment for passport renewal MQ1PITU0 is set for [REDACTED_NER]] at [REDACTED_NER], [REDACTED_NER]. The confirmation email is sent to [REDACTED_CUSTOM].', 'Prof. [REDACTED_NER] requested a copy of the transaction with IBAN GB37 AGLF [REDACTED_CUSTOM] to be sent to [REDACTED_CUSTOM]. For more details, visit [REDACTED] or dial ([REDACTED_CUSTOM].', 'Dr. [REDACTED_NER] reported a fraudulent charge on their card [REDACTED_CRED] on [REDACTED_NER]REDACTED]. Contact details: [REDACTED_CUSTOM], [REDACTED].', \"[REDACTED_NER] with driver's license [REDACTED_CUSTOM] requested roadside assistance at [REDACTED_NER] on [REDACTED] [REDACTED]. For updates, contact ++[REDACTED_CUSTOM].\", \"The car rental for Dr. [REDACTED_NER] with driver's license VI-[REDACTED] was processed on [REDACTED] [REDACTED]. The transaction ID GB04 TPER [REDACTED_CUSTOM] was sent to [REDACTED].\", '[REDACTED_NER], with nationality [REDACTED_NER], scheduled a service at 742 Steele Lodge, [REDACTED_NER], [REDACTED_NER] 59043 for [REDACTED] [REDACTED]. Confirmation sent to [REDACTED]. Remember to bring ID IN-[REDACTED] and SSN[REDACTED_CUSTOM].', 'Welcome message sent to Prof. [REDACTED_NER] at [REDACTED]. Instructions to set up their new account[REDACTED_CUSTOM] are included. IP 800b:bff5:2920:9a30:1d5e:b7d7:f933:6a6c was used for signup.', 'Ms. [REDACTED_NER] confirmed their attendance for the webinar on [REDACTED] [REDACTED] at [REDACTED_NER], [REDACTED_NER]. Registration details: SSN[REDACTED_CUSTOM], contact[REDACTED_CUSTOM], and nationality [REDACTED_NER].', '[REDACTED_NER] new credit card [REDACTED_CUSTOM] was activated on [REDACTED] [REDACTED] after identity verification with SSN[REDACTED_CUSTOM] was completed. Confirmation email sent to [REDACTED].', 'A change in address for [REDACTED_NER] account[REDACTED_CUSTOM] was logged at [REDACTED_NER] on [REDACTED_NER].', '[REDACTED_NER] transaction to GB44 TINQ [REDACTED_CUSTOM] from account[REDACTED_CUSTOM] was completed on [REDACTED_NER]. For security, SSN[REDACTED_CUSTOM] was verified and email confirmation sent to [REDACTED_CUSTOM].', '[REDACTED_NER] new credit card [REDACTED_CUSTOM] was activated on [REDACTED_NER] after identity verification with SSN[REDACTED_CUSTOM] was completed. Confirmation email sent to [REDACTED].', 'Guest [REDACTED_NER] with passport number 9ML16BAL checked in at Port Thomasburgh on [REDACTED_NER]REDACTED]. Billing info: credit card [REDACTED_CRED], contact email [REDACTED_CUSTOM].', '[REDACTED_NER] updated their emergency contact details to (216)431-7314x560. The security question linked to SSN[REDACTED_CUSTOM] and bank account[REDACTED_CUSTOM] was also updated.', 'Confirmation for [REDACTED_NER]: Your transaction to [REDACTED_IBAN] from account [REDACTED_CUSTOM] is complete. Details were sent to [REDACTED] and can be reviewed at [REDACTED]', \"New login to [REDACTED] by [REDACTED_NER] using ITIN[REDACTED_CUSTOM] from [REDACTED] on [REDACTED] [REDACTED]. If this wasn't you, please notify us immediately at [REDACTED_CUSTOM].\", '[REDACTED_NER] account[REDACTED_CUSTOM] was accessed from IP aaa6:62a5:5f8a:42ce:9040:e8d8:c403:c2de on [REDACTED_NER]. Verification code sent to [REDACTED].', 'New card [REDACTED_CUSTOM] linked to [REDACTED_NER] account[REDACTED_CUSTOM] was activated on [REDACTED] [REDACTED]. Confirmation email sent to [REDACTED_CUSTOM].', 'A new connection from IP [REDACTED] was detected on [REDACTED] [REDACTED] for [REDACTED_NER] account. Please verify recent activities with your bank[REDACTED_CUSTOM].', 'Email to [REDACTED_NER]: Your recent transaction from GB63 IWZD [REDACTED_CUSTOM] has been flagged. Please verify recent activity using your SSN[REDACTED_CUSTOM] at [REDACTED]', '[REDACTED_NER] confirmed their attendance for the webinar on [REDACTED_NER]] at 54660 Brown Circles, [REDACTED_NER], [REDACTED_NER] 92394. Registration details: SSN[REDACTED_CUSTOM], contact 532-992-6562x577, and nationality [REDACTED_NER].', 'Password reset request for [REDACTED_NER] was received from IP 45e5:8989:1f5e:75c7:2ed6:5cdd:a952:b311. To confirm, use SSN[REDACTED_CUSTOM] and bank number[REDACTED_CUSTOM], or contact 608.586.0905.', 'User [REDACTED_NER], with ITIN[REDACTED_CUSTOM], accessed [REDACTED] on [REDACTED_NER]] from IP [REDACTED]. For account support related to[REDACTED_CUSTOM], contact[REDACTED_CUSTOM]-3392x974.', 'During our regular audit on [REDACTED] [REDACTED], we verified the account[REDACTED_CUSTOM] and ITIN[REDACTED_CUSTOM] for Ms. [REDACTED_NER] against the national database [REDACTED_NER].', '[REDACTED_NER], residing at [REDACTED_NER], [REDACTED_NER], reported a lost credit card [REDACTED_CRED] to the hotline 396.518.6255 on [REDACTED_NER]. A freeze was placed on their account[REDACTED_CUSTOM].', \"Notice for [REDACTED_NER]: Your recent application using SSN[REDACTED_CUSTOM] and driver's license CO-[REDACTED] has been approved. Please confirm your email [REDACTED].\", \"[REDACTED_NER] ITIN[REDACTED_CUSTOM] and driver's license NM-[REDACTED_CUSTOM] were used to process a transaction on [REDACTED_NER]REDACTED].\", \"Mrs. [REDACTED_NER]'s credit card [REDACTED_CRED] was charged on [REDACTED_NER] for the purchase. Receipt sent to [REDACTED]. Call[REDACTED_CUSTOM]-2857x92088 for disputes.\", '[REDACTED_NER] reported a fraudulent charge on their card [REDACTED_CRED] on [REDACTED] [REDACTED]. Contact details: 762-935-7368x61893, [REDACTED].', 'Security update: [REDACTED_NER], your password for account[REDACTED_CUSTOM] was reset on [REDACTED] [REDACTED]. A notification was sent to [REDACTED] from [REDACTED].', '[REDACTED_NER] flagged a suspicious transaction made to [REDACTED_IBAN] from account[REDACTED_CUSTOM] on [REDACTED] [REDACTED].', 'Car loan approved for Ms. [REDACTED_NER] on [REDACTED_NER]REDACTED]. Vehicle to be picked up at [REDACTED_NER], [REDACTED_NER] ([REDACTED_NER]). Loan details: account[REDACTED_CUSTOM], phone (615)425-5171x0591.', 'Ms. [REDACTED_NER] updated their payment details for account[REDACTED_CUSTOM] with IBAN GB82 DEZL [REDACTED_CUSTOM]. New email [REDACTED_CUSTOM] and phone[REDACTED_CUSTOM]-2880x498 were confirmed.', '[REDACTED_NER] updated their emergency contact details to (450)606-9874x361. The security question linked to SSN[REDACTED_CUSTOM] and bank account [REDACTED_CUSTOM] was also updated.', \"Customer notice for Ms. [REDACTED_NER]: Your driver's license MO-[REDACTED_CUSTOM] and passport FEY8LM73 need renewal before [REDACTED] [REDACTED]. Visit New Elizabeth, [REDACTED_NER] or contact +1-269-993-3200x354.\", '[REDACTED_NER] with ITIN[REDACTED_CUSTOM] made a purchase on [REDACTED] on [REDACTED] [REDACTED]. Shipping to [REDACTED_NER]. Payment was made using bank account[REDACTED_CUSTOM].', 'Our records show [REDACTED_NER], nationality Neo-Paganism, booked a flight using passport number 0D15MV0U6. Confirmation was sent to [REDACTED_CUSTOM] and can be tracked at [REDACTED]', 'Ms. [REDACTED_NER] updated their SSN[REDACTED_CUSTOM] and phone 512.244.2025 for their account[REDACTED_CUSTOM] on [REDACTED] [REDACTED].', '[REDACTED_NER] confirmed their identity with ITIN[REDACTED_CUSTOM] and email [REDACTED_CUSTOM] on [REDACTED_NER]REDACTED].', 'During our regular audit on [REDACTED_NER]], we verified the account[REDACTED_CUSTOM] and ITIN[REDACTED_CUSTOM] for [REDACTED_NER] against the national database [REDACTED_NER].', '[REDACTED_NER] logged into [REDACTED] from IP ad06:da0d:1f1f:9aeb:6af5:6157:c024:fd03 to review transactions for[REDACTED_CUSTOM]. Contact ++[REDACTED_CUSTOM]-9084x705 for assistance.', '[REDACTED_NER] flagged a suspicious transaction made to [REDACTED_IBAN] from account [REDACTED_CUSTOM] on [REDACTED_NER]REDACTED].', \"[REDACTED_NER] new driver's license ND-[REDACTED_CUSTOM] was issued on [REDACTED] [REDACTED] and sent to their registered email [REDACTED].\", '[REDACTED_NER] confirmed their attendance for the webinar on [REDACTED] [REDACTED] at 773 Kimberly Gateway Apt. 458, [REDACTED_NER], [REDACTED_NER] 36568. Registration details: SSN[REDACTED_CUSTOM], contact ++1 671 ([REDACTED_CUSTOM], and nationality [REDACTED_NER].', \"Mr. [REDACTED_NER]'s card [REDACTED_CUSTOM] was used to make a purchase on [REDACTED] [REDACTED]. Confirmation sent to [REDACTED_CUSTOM].\", 'New IP address be0b:6295:3d6:af1a:e30d:5ee3:dce6:e5f4 logged for [REDACTED_NER] account on [REDACTED] [REDACTED]. Confirm changes via [REDACTED] or call[REDACTED_CUSTOM]-8293x4143.', '[REDACTED_NER] account[REDACTED_CUSTOM] was accessed from IP a6af:53f7:7f39:7437:5dab:56f3:2366:bb6c on [REDACTED] [REDACTED]. Verification code sent to [REDACTED].', \"Dr. [REDACTED_NER]'s transaction to [REDACTED_IBAN] from account [REDACTED_CUSTOM] was completed on [REDACTED_NER]]. For security, SSN[REDACTED_CUSTOM] was verified and email confirmation sent to [REDACTED_CUSTOM].\", 'New device setup by Mr. [REDACTED_NER] completed. IP 7b21:9bfe:72c6:40cf:b430:5c5e:63b2:2e4b and device ID linked to email [REDACTED_CUSTOM] and bank account [REDACTED_CUSTOM].', 'Prof. [REDACTED_NER] flagged a suspicious transaction made to GB87 SFHD [REDACTED_CUSTOM] from account[REDACTED_CUSTOM] on [REDACTED] [REDACTED].', \"Mr. [REDACTED_NER] with driver's license MN-[REDACTED] requested roadside assistance at Unit 2364 Box 9220, DPO AP 24840 on [REDACTED_NER]. For updates, contact[REDACTED_CUSTOM]-0664x8817.\", \"Mr. [REDACTED_NER]'s ITIN[REDACTED_CUSTOM] and driver's license IL-[REDACTED] were used to process a transaction on [REDACTED_NER].\", \"Notification: Ms. [REDACTED_NER]'s driver's license [REDACTED_CUSTOM] is set to expire on [REDACTED_NER]]. Renewal details have been sent to [REDACTED_CUSTOM].\", 'Customer Ms. [REDACTED_NER] made a purchase on [REDACTED_NER]] using card [REDACTED_CUSTOM]. A loyalty discount was applied. Email [REDACTED_CUSTOM] for membership details.', 'Notification: [REDACTED_NER] request to transfer funds from[REDACTED_CUSTOM] to [REDACTED_NER] [REDACTED_[REDACTED_NER]] was completed on [REDACTED_NER]REDACTED].', 'Alarm raised for [REDACTED_NER] at [REDACTED] [REDACTED]: An attempt to access [REDACTED] using [REDACTED] with the email [REDACTED_CUSTOM]. Bank account[REDACTED_CUSTOM] has been put on hold.', 'A request to update [REDACTED_NER] email [REDACTED_CUSTOM] was submitted on [REDACTED_NER]]. Contact[REDACTED_CUSTOM]-9898x91120 for any issues.', 'Our records show Mr. [REDACTED_NER], nationality [REDACTED_NER], booked a flight using passport number O97PC1MB. Confirmation was sent to [REDACTED] and can be tracked at [REDACTED]', '[REDACTED_NER], with nationality [REDACTED_NER], scheduled a service at North Carla for [REDACTED] [REDACTED]. Confirmation sent to [REDACTED_CUSTOM]. Remember to bring ID IN-[REDACTED_CUSTOM] and SSN[REDACTED_CUSTOM].', 'Order confirmation for [REDACTED_NER]: Shipment to 894 Sanders Knolls Suite 700, [REDACTED_NER], [REDACTED_NER] will arrive on [REDACTED] [REDACTED]. Tracking available at [REDACTED] Contact us at[REDACTED_CUSTOM] for issues.', '[REDACTED_NER] filed a dispute over the transaction made to [REDACTED_NER] [REDACTED_CUSTOM] on [REDACTED_NER]]. Bank account[REDACTED_CUSTOM] and IP 1340:8312:d941:89e3:9eac:75fb:b39d:1d51 were flagged.', \"Mr. [REDACTED_NER]'s credit card [REDACTED_CUSTOM] was charged on [REDACTED_NER] for the purchase. Receipt sent to [REDACTED_CUSTOM]. Call +1-[REDACTED_CUSTOM] for disputes.\", 'A travel booking for [REDACTED_NER] with passport F78EKN0NL was completed on [REDACTED] [REDACTED] and confirmed at [REDACTED_CUSTOM].', 'A transfer to GB45 BOZP [REDACTED_CUSTOM] from[REDACTED_CUSTOM] was initiated on [REDACTED] [REDACTED] by [REDACTED_NER], holder of passport P9U49EJ0. Any queries should be directed to ++[REDACTED_CUSTOM]-3968x6647 or [REDACTED_CUSTOM].', '[REDACTED_NER] requested a credit increase for card [REDACTED_CUSTOM] on [REDACTED_NER]. New terms sent to [REDACTED_CUSTOM]. For questions, contact 548-239-0494x0931.', 'Our new client [REDACTED_NER] with ITIN[REDACTED_CUSTOM] has registered for online banking. Account [REDACTED_CUSTOM], IP 348:a607:483f:83b0:a208:d5bc:48d9:4884, email [REDACTED] are now linked.', 'A transfer to [REDACTED_IBAN] from[REDACTED_CUSTOM] was initiated on [REDACTED_NER] [REDACTED_NER], holder of passport PRXC151I. Any queries should be directed to ++[REDACTED_CUSTOM]-3041x74789 or [REDACTED].', '[REDACTED_NER] requested a copy of the transaction with [REDACTED_NER] [REDACTED_CUSTOM] to be sent to [REDACTED_CUSTOM]. For more details, visit https://blog.wells.info.biz/contact-us?filter=active#section or dial ++[REDACTED_CUSTOM].', '[REDACTED_NER] new credit card [REDACTED_CUSTOM]-965 was activated on [REDACTED_NER]] after identity verification with SSN[REDACTED_CUSTOM] was completed. Confirmation email sent to [REDACTED].', 'Welcome Prof. [REDACTED_NER] to our service! Your account[REDACTED_CUSTOM] is now active. Log in from 479:9450:e9ff:a8fc:6324:191d:1c64:12cf, or call us at ++[REDACTED_CUSTOM]-4902x6806 for support.', 'Customer [REDACTED_NER] made a purchase on [REDACTED] [REDACTED] using card [REDACTED_CUSTOM]. A loyalty discount was applied. Email [REDACTED] for membership details.', 'New device setup by Dr. [REDACTED_NER] completed. IP [REDACTED] and device ID linked to email [REDACTED_CUSTOM] and bank account[REDACTED_CUSTOM].', '[REDACTED_NER] confirmed their attendance for the webinar on [REDACTED_NER] at New Jessicaland. Registration details: SSN[REDACTED_CUSTOM], contact 731.222.1007, and nationality Neo-Paganism.', 'Confirmation for Mr. [REDACTED_NER]: Your transaction to GB09 XUZC [REDACTED_CUSTOM] from account[REDACTED_CUSTOM] is complete. Details were sent to [REDACTED] and can be reviewed at [REDACTED]', '[REDACTED_NER] changed their billing address for their credit card [REDACTED_CUSTOM] to [REDACTED_NER], [REDACTED_NER] on [REDACTED_NER].', \"Dr. [REDACTED_NER]'s card [REDACTED_CUSTOM] was used to make a purchase on [REDACTED] [REDACTED]. Confirmation sent to [REDACTED_CUSTOM].\", '[REDACTED_NER] appointment for passport renewal INFGXLY2 is set for [REDACTED] [REDACTED] at [REDACTED_NER], [REDACTED_NER] [REDACTED_NER]. The confirmation email is sent to [REDACTED_CUSTOM].', \"Notification: Ms. [REDACTED_NER]'s request to transfer funds from[REDACTED_CUSTOM] to IBAN GB03 WWAR [REDACTED_CUSTOM] was completed on [REDACTED_NER].\", 'Account[REDACTED_CUSTOM] owned by [REDACTED_NER] was accessed on [REDACTED_NER] from new IP [REDACTED]. Verify the activity through [REDACTED] or contact support at[REDACTED_CUSTOM]-8536x2586.', '[REDACTED_NER] account [REDACTED_CUSTOM] was accessed from IP [REDACTED] on [REDACTED] [REDACTED]. Verification code sent to [REDACTED_CUSTOM].']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning custom model using spacy3.0"
      ],
      "metadata": {
        "id": "T8F8b-OiWZRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetuning custom model using spacy3.0\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "# Use a subset of the training data for finetuning the model.sample_set comes from the generated synthetic dataset.\n",
        "TRAIN_DATA = sample_set[0:1000]  # Use the first 100 records for training.\n",
        "\n",
        "#nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "nlp = spacy.load(\"en_core_web_trf\") # load other spacy model\n",
        "\n",
        "db = DocBin() # create a DocBin object\n",
        "for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "\n",
        "# os.chdir(r'XXXX\\XXXXX')\n",
        "db.to_disk(\"./train.spacy\") # save the docbin object"
      ],
      "metadata": {
        "id": "TwIkf29odNBn",
        "outputId": "f4dd540d-17ce-4d02-f45f-6de678f7c2c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 216/1000 [00:00<00:00, 1086.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 715/1000 [00:00<00:00, 1189.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1156.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "id": "U4gfC8VwdaIF",
        "outputId": "2d1438eb-65df-4044-a4e6-96bae5445119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy"
      ],
      "metadata": {
        "id": "oK0qgmROeWVW",
        "outputId": "dacb51d9-f18a-4a43-8f91-0a2091e536e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     39.90    0.00    0.00    0.00    0.00\n",
            "  0     200       1096.23   5040.27   71.91   73.34   70.54    0.72\n",
            "  1     400        512.10   1216.68   96.74   96.54   96.94    0.97\n",
            "  2     600        497.81    488.10   99.23   99.18   99.29    0.99\n",
            "  3     800       1031.12    155.58   99.56   99.59   99.53    1.00\n",
            "  4    1000         88.04     70.80   99.84   99.84   99.84    1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# Load the model (adjust the path if needed)\n",
        "nlp1 = spacy.load(\"/content/output/model-best\")  # Ensures the model is uploaded in Colab's environment\n",
        "\n",
        "# Sample input text\n",
        "doc = nlp1(\"Kyle Williams, residing at Wilcoxland, updated their contact information to ++44 7781 (891)733-0984x46212 and jeremy48@gray.com. Their account 0525617716 and SSN 522-89-8848 were noted for the update.\")\n",
        "\n",
        "# Render the named entities in the text (for Colab, use jupyter=False or render HTML)\n",
        "html = displacy.render(doc, style=\"ent\", jupyter=False)\n",
        "\n",
        "# To display in Colab, render the HTML in an output cell\n",
        "from IPython.display import display, HTML\n",
        "display(HTML(html))"
      ],
      "metadata": {
        "id": "dJgf6Fu3mHTu",
        "outputId": "42d15547-1a0d-41cd-83c3-59bf55ba25af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kyle Williams\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", residing at \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Wilcoxland\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
              "</mark>\n",
              ", updated their contact information to \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ++44 7781 (891)733-0984x46212\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PHONE_NUMBER</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    jeremy48@gray.com\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMAIL_ADDRESS</span>\n",
              "</mark>\n",
              ". Their account \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    0525617716\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BANK_NUMBER</span>\n",
              "</mark>\n",
              " and SSN \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    522-89-8848\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SSN</span>\n",
              "</mark>\n",
              " were noted for the update.</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def redact_pii_content(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    redacted_text = text\n",
        "    for ent in doc.ents:\n",
        "        redacted_text = redacted_text.replace(ent.text, '[REDACTED]')\n",
        "    return redacted_text\n",
        "\n",
        "# Loaded NER model as 'nlp1'\n",
        "nlp1 = spacy.load(\"./output/model-best\")\n",
        "\n",
        "sample_set_new = redacted_texts   # Assuming you have your sample set defined here\n",
        "\n",
        "redacted_texts_new = []\n",
        "\n",
        "for text in sample_set_new:\n",
        "    redacted_text = redact_pii_content(text, nlp1)\n",
        "    redacted_texts_new.append(redacted_text)\n",
        "\n",
        "print(len(sample_set_new))\n",
        "\n",
        "# Example output\n",
        "for original, redacted in zip(sample_set_new, redacted_texts_new[:2]):\n",
        "    print(\"Original:\", original[0])\n",
        "    print(\"Redacted:\", redacted)\n",
        "    print(\"-------\")"
      ],
      "metadata": {
        "id": "axA601D-me_g",
        "outputId": "c08b71d3-d967-486f-c1a7-c3510b748fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "Original: U\n",
            "Redacted: User [[[REDACTED]]]], with ITIN[[REDACTED]]_CUSTOM], accessed [[REDACTED]]] on [[REDACTED]]] [[REDACTED]]] from IP [REDACTED]. For account support related to[[REDACTED]]_CUSTOM], contact[[REDACTED]]_CUSTOM].\n",
            "-------\n",
            "Original: [\n",
            "Redacted: [[[REDACTED]]] confirmed their attendance for the webinar on [[REDACTED]] [[REDACTED]] at [[[REDACTED]]], [[[REDACTED]]]. Registration details: SSN[[REDACTED]_CUSTOM], contact ++[[REDACTED]_CUSTOM], and nationality [[[REDACTED]]].\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_unredacted_entities(original_text, redacted_text, entities):\n",
        "    unredacted_count = 0\n",
        "    for start, end, _ in entities:\n",
        "        entity_text = original_text[start:end]\n",
        "        # Check if the entity text is still present in the redacted text\n",
        "        if entity_text in redacted_text:\n",
        "            unredacted_count += 1\n",
        "    return unredacted_count\n",
        "\n",
        "def calculate_performance_metrics(annotated_data, redacted_texts):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    for ((text, annotation), redacted_text) in zip(annotated_data, redacted_texts):\n",
        "        entities = annotation['entities']\n",
        "        redacted_count = redacted_text.count('[REDACTED]')\n",
        "\n",
        "        TP += len(entities) - count_unredacted_entities(text, redacted_text, entities)  # Adjusted TP calculation\n",
        "        FN += count_unredacted_entities(text, redacted_text, entities)  # Now actually calculates FNs\n",
        "        FP += max(0, redacted_count - len(entities))  # Extra redactions are considered FPs\n",
        "\n",
        "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "    # Print results and the list of unredacted entities\n",
        "    print(f\"\\nTrue Positives (Correct Redactions): {TP}\")\n",
        "    print(f\"False Positives (Over-redactions): {FP}\")\n",
        "    print(f\"False Negatives (Missed Redactions): {FN}\\n\")\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "# Example usage\n",
        "precision, recall, f1_score = calculate_performance_metrics(sample_set[0:1023], redacted_texts_new)\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1_score:.2f}\")\n",
        "\n",
        "print(len(spacy_training_data))"
      ],
      "metadata": {
        "id": "-qGjTHJxmsxa",
        "outputId": "19ffd0c5-deb6-4229-b712-e70744688d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493 56 2\n",
            "Precision: 0.90, Recall: 1.00, F1 Score: 0.94\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "# Assuming you've already loaded your trained NER model\n",
        "nlp = spacy.load(\"./output/model-best\")  # Path to your fine-tuned model\n",
        "\n",
        "# Function to read a text file\n",
        "def read_file_content(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Function to save the redacted text to a new file\n",
        "def save_to_file(redacted_text, output_file):\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(redacted_text)\n",
        "\n",
        "# Function to detect and redact PII using the NER model\n",
        "def redact_pii_content(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    redacted_text = text\n",
        "    for ent in doc.ents:\n",
        "        redacted_text = redacted_text.replace(ent.text, '[REDACTED]')\n",
        "    return redacted_text\n",
        "\n",
        "# Main function to process the input file\n",
        "def redact_pii_in_file(input_file, output_file):\n",
        "    # Step 1: Read the text from the input file\n",
        "    original_text = read_file_content(input_file)\n",
        "\n",
        "    # Step 2: Detect and redact PII in the text using the NER model\n",
        "    redacted_text = redact_pii_content(original_text, nlp)\n",
        "\n",
        "    # Step 3: Save the redacted text to the output file\n",
        "    save_to_file(redacted_text, output_file)\n",
        "\n",
        "    print(f\"Redacted text saved to {output_file}\")\n",
        "\n",
        "# Example usage:\n",
        "input_file_path = \"input_file.txt\"  # Replace with your input file path\n",
        "output_file_path = \"redacted_output_file.txt\"  # Replace with your desired output file path\n",
        "\n",
        "# Call the function to redact PII in the input file\n",
        "redact_pii_in_file(input_file_path, output_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01A7g0_OFK5a",
        "outputId": "85999c1b-0899-4511-be88-a4bec21abee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redacted text saved to redacted_output_file.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load your trained NER model\n",
        "nlp = spacy.load(\"./output/model-best\")  # Path to your fine-tuned model\n",
        "\n",
        "# Function to read a text file\n",
        "def read_file_content(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()\n",
        "\n",
        "# Function to save the redacted text to a new file\n",
        "def save_to_file(redacted_text, output_file):\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(redacted_text)\n",
        "\n",
        "# Function to detect and redact PII using the NER model\n",
        "def redact_pii_content(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    redacted_text = text\n",
        "    for ent in doc.ents:\n",
        "        redacted_text = redacted_text.replace(ent.text, '[REDACTED]')\n",
        "    return redacted_text\n",
        "\n",
        "# Function to measure and print the detect and redact time\n",
        "def redact_pii_in_file(input_file, output_file):\n",
        "    # Step 1: Read the text from the input file\n",
        "    original_text = read_file_content(input_file)\n",
        "\n",
        "    # Step 2: Measure detection and redaction time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Detect and redact PII\n",
        "    redacted_text = redact_pii_content(original_text, nlp)\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    # Step 3: Save the redacted text to the output file\n",
        "    save_to_file(redacted_text, output_file)\n",
        "\n",
        "    # Step 4: Print the total detection and redaction time\n",
        "    print(f\"Redacted text saved to {output_file}\")\n",
        "    print(f\"Detection and Redaction Time: {total_time:.2f} seconds\")\n",
        "\n",
        "# Example usage:\n",
        "input_file_path = \"dataset_1000.txt\"  # Replace with your input file path\n",
        "output_file_path = \"redacted_output_file.txt\"  # Replace with your desired output file path\n",
        "\n",
        "# Call the function to redact PII in the input file and measure time\n",
        "redact_pii_in_file(input_file_path, output_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moxjexaRjpOt",
        "outputId": "8e6d0b87-b2b4-4f77-ab0a-d26aa5896e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redacted text saved to redacted_output_file.txt\n",
            "Detection and Redaction Time: 17.98 seconds\n"
          ]
        }
      ]
    }
  ]
}